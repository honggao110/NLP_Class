{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP Homework 1 - Hyperparameter tuning part\n",
    "\n",
    "### IMDB Movie Review Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The models will be based on 4-gram model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import spacy\n",
    "import string\n",
    "import os\n",
    "import pickle as pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_tokens = pkl.load(open(\"train_data_tokens_3gram.p\", \"rb\"))\n",
    "all_train_tokens = pkl.load(open(\"all_train_tokens_3gram.p\", \"rb\"))\n",
    "val_data_tokens = pkl.load(open(\"val_data_tokens_3gram.p\", \"rb\"))\n",
    "test_data_tokens = pkl.load(open(\"test_data_tokens_3gram.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = pkl.load(open(\"train_label.p\", \"rb\"))\n",
    "val_label = pkl.load(open(\"val_label.p\", \"rb\"))\n",
    "test_label = pkl.load(open(\"test_label.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test different vocabulary size in the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "token_counter = Counter(all_train_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4326527"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test vocabulary size\n",
    "Since there are 4,326,527 total vocabularies in the counter, 10,000 vocabulary size in the baseline model is too low. Try different sizes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "try_vocab_size = [25000, 50000, 100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_vocab(all_tokens):\n",
    "    # Returns:\n",
    "    # id2token: list of tokens, where id2token[i] returns token that corresponds to token i\n",
    "    # token2id: dictionary where keys represent tokens and corresponding values represent indices\n",
    "    token_counter = Counter(all_tokens)\n",
    "    vocab, count = zip(*token_counter.most_common(max_vocab_size))\n",
    "    id2token = list(vocab)\n",
    "    token2id = dict(zip(vocab, range(2,2+len(vocab)))) \n",
    "    id2token = ['<pad>', '<unk>'] + id2token\n",
    "    token2id['<pad>'] = PAD_IDX \n",
    "    token2id['<unk>'] = UNK_IDX\n",
    "    return token2id, id2token\n",
    "\n",
    "def token2index_dataset(tokens_data):\n",
    "    indices_data = []\n",
    "    for tokens in tokens_data:\n",
    "        index_list = [token2id[token] if token in token2id else UNK_IDX for token in tokens]\n",
    "        indices_data.append(index_list)\n",
    "    return indices_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class NewsGroupDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
    "    Note that this class inherits torch.utils.data.Dataset\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data_list, target_list):\n",
    "        \"\"\"\n",
    "        @param data_list: list of newsgroup tokens \n",
    "        @param target_list: list of newsgroup targets \n",
    "\n",
    "        \"\"\"\n",
    "        self.data_list = data_list\n",
    "        self.target_list = target_list\n",
    "        assert (len(self.data_list) == len(self.target_list))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "        \n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        \n",
    "        token_idx = self.data_list[key][:MAX_SENTENCE_LENGTH]\n",
    "        label = self.target_list[key]\n",
    "        return [token_idx, len(token_idx), label]\n",
    "\n",
    "def newsgroup_collate_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all \n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    label_list = []\n",
    "    length_list = []\n",
    "    #print(\"collate batch: \", batch[0][0])\n",
    "    #batch[0][0] = batch[0][0][:MAX_SENTENCE_LENGTH]\n",
    "    for datum in batch:\n",
    "        label_list.append(datum[2])\n",
    "        length_list.append(datum[1])\n",
    "    # padding\n",
    "    for datum in batch:\n",
    "        padded_vec = np.pad(np.array(datum[0]), \n",
    "                                pad_width=((0,MAX_SENTENCE_LENGTH-datum[1])), \n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        data_list.append(padded_vec)\n",
    "    return [torch.from_numpy(np.array(data_list)), torch.LongTensor(length_list), torch.LongTensor(label_list)]\n",
    "\n",
    "# Function for testing the model\n",
    "def test_model(loader, model):\n",
    "    \"\"\"\n",
    "    Help function that tests the model's performance on a dataset\n",
    "    @param: loader - data loader for the dataset to test against\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    for data, lengths, labels in loader:\n",
    "        data_batch, length_batch, label_batch = data, lengths, labels\n",
    "        outputs = F.softmax(model(data_batch, length_batch), dim=1)\n",
    "        predicted = outputs.max(1, keepdim=True)[1]\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels.view_as(predicted)).sum().item()\n",
    "    return (100 * correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BagOfWords(nn.Module):\n",
    "    \"\"\"\n",
    "    BagOfWords classification model\n",
    "    \"\"\"\n",
    "    def __init__(self, vocab_size, emb_dim):\n",
    "        \"\"\"\n",
    "        @param vocab_size: size of the vocabulary. \n",
    "        @param emb_dim: size of the word embedding\n",
    "        \"\"\"\n",
    "        super(BagOfWords, self).__init__()\n",
    "        # pay attention to padding_idx \n",
    "        self.embed = nn.Embedding(vocab_size, emb_dim, padding_idx=0)\n",
    "        self.linear = nn.Linear(emb_dim,20)\n",
    "    \n",
    "    def forward(self, data, length):\n",
    "        \"\"\"\n",
    "        \n",
    "        @param data: matrix of size (batch_size, max_sentence_length). Each row in data represents a \n",
    "            review that is represented using n-gram index. Note that they are padded to have same length.\n",
    "        @param length: an int tensor of size (batch_size), which represents the non-trivial (excludes padding)\n",
    "            length of each sentences in the data.\n",
    "        \"\"\"\n",
    "        out = self.embed(data)\n",
    "        out = torch.sum(out, dim=1)\n",
    "        out /= length.view(length.size()[0],1).expand_as(out).float()\n",
    "     \n",
    "        # return logits\n",
    "        out = self.linear(out.float())\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "MAX_SENTENCE_LENGTH = 200\n",
    "BATCH_SIZE = 32\n",
    "learning_rate = 0.01\n",
    "num_epochs = 10\n",
    "emb_dim = 100 # bigger is better, 200, 500...\n",
    "criterion = torch.nn.CrossEntropyLoss()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/10], Step: [301/625], Validation Acc: 85.2\n",
      "Epoch: [1/10], Step: [601/625], Validation Acc: 86.32\n",
      "Epoch: [2/10], Step: [301/625], Validation Acc: 86.38\n",
      "Epoch: [2/10], Step: [601/625], Validation Acc: 86.08\n",
      "Epoch: [3/10], Step: [301/625], Validation Acc: 85.14\n",
      "Epoch: [3/10], Step: [601/625], Validation Acc: 84.98\n",
      "Epoch: [4/10], Step: [301/625], Validation Acc: 85.46\n",
      "Epoch: [4/10], Step: [601/625], Validation Acc: 82.64\n",
      "Epoch: [5/10], Step: [301/625], Validation Acc: 84.88\n",
      "Epoch: [5/10], Step: [601/625], Validation Acc: 84.0\n",
      "Epoch: [6/10], Step: [301/625], Validation Acc: 83.9\n",
      "Epoch: [6/10], Step: [601/625], Validation Acc: 83.78\n",
      "Epoch: [7/10], Step: [301/625], Validation Acc: 83.64\n",
      "Epoch: [7/10], Step: [601/625], Validation Acc: 84.08\n",
      "Epoch: [8/10], Step: [301/625], Validation Acc: 84.08\n",
      "Epoch: [8/10], Step: [601/625], Validation Acc: 83.62\n",
      "Epoch: [9/10], Step: [301/625], Validation Acc: 83.7\n",
      "Epoch: [9/10], Step: [601/625], Validation Acc: 83.58\n",
      "Epoch: [10/10], Step: [301/625], Validation Acc: 83.66\n",
      "Epoch: [10/10], Step: [601/625], Validation Acc: 83.56\n",
      "Vocab Size: 25000, Validation Acc: 83.3\n",
      "Epoch: [1/10], Step: [301/625], Validation Acc: 85.5\n",
      "Epoch: [1/10], Step: [601/625], Validation Acc: 86.96\n",
      "Epoch: [2/10], Step: [301/625], Validation Acc: 86.78\n",
      "Epoch: [2/10], Step: [601/625], Validation Acc: 86.96\n",
      "Epoch: [3/10], Step: [301/625], Validation Acc: 85.94\n",
      "Epoch: [3/10], Step: [601/625], Validation Acc: 84.36\n",
      "Epoch: [4/10], Step: [301/625], Validation Acc: 85.4\n",
      "Epoch: [4/10], Step: [601/625], Validation Acc: 85.12\n",
      "Epoch: [5/10], Step: [301/625], Validation Acc: 85.34\n",
      "Epoch: [5/10], Step: [601/625], Validation Acc: 84.44\n",
      "Epoch: [6/10], Step: [301/625], Validation Acc: 85.46\n",
      "Epoch: [6/10], Step: [601/625], Validation Acc: 85.34\n",
      "Epoch: [7/10], Step: [301/625], Validation Acc: 85.4\n",
      "Epoch: [7/10], Step: [601/625], Validation Acc: 85.08\n",
      "Epoch: [8/10], Step: [301/625], Validation Acc: 85.12\n",
      "Epoch: [8/10], Step: [601/625], Validation Acc: 84.96\n",
      "Epoch: [9/10], Step: [301/625], Validation Acc: 85.06\n",
      "Epoch: [9/10], Step: [601/625], Validation Acc: 84.94\n",
      "Epoch: [10/10], Step: [301/625], Validation Acc: 84.84\n",
      "Epoch: [10/10], Step: [601/625], Validation Acc: 84.96\n",
      "Vocab Size: 50000, Validation Acc: 85.06\n",
      "Epoch: [1/10], Step: [301/625], Validation Acc: 85.64\n",
      "Epoch: [1/10], Step: [601/625], Validation Acc: 87.24\n",
      "Epoch: [2/10], Step: [301/625], Validation Acc: 86.9\n",
      "Epoch: [2/10], Step: [601/625], Validation Acc: 86.06\n",
      "Epoch: [3/10], Step: [301/625], Validation Acc: 86.56\n",
      "Epoch: [3/10], Step: [601/625], Validation Acc: 86.44\n",
      "Epoch: [4/10], Step: [301/625], Validation Acc: 86.48\n",
      "Epoch: [4/10], Step: [601/625], Validation Acc: 86.22\n",
      "Epoch: [5/10], Step: [301/625], Validation Acc: 86.22\n",
      "Epoch: [5/10], Step: [601/625], Validation Acc: 86.14\n",
      "Epoch: [6/10], Step: [301/625], Validation Acc: 86.14\n",
      "Epoch: [6/10], Step: [601/625], Validation Acc: 85.86\n",
      "Epoch: [7/10], Step: [301/625], Validation Acc: 86.1\n",
      "Epoch: [7/10], Step: [601/625], Validation Acc: 85.98\n",
      "Epoch: [8/10], Step: [301/625], Validation Acc: 85.94\n",
      "Epoch: [8/10], Step: [601/625], Validation Acc: 85.94\n",
      "Epoch: [9/10], Step: [301/625], Validation Acc: 86.1\n",
      "Epoch: [9/10], Step: [601/625], Validation Acc: 86.06\n",
      "Epoch: [10/10], Step: [301/625], Validation Acc: 86.24\n",
      "Epoch: [10/10], Step: [601/625], Validation Acc: 86.08\n",
      "Vocab Size: 100000, Validation Acc: 85.98\n"
     ]
    }
   ],
   "source": [
    "for size in try_vocab_size:\n",
    "    # building vocabulary and convert to indices\n",
    "    max_vocab_size = size\n",
    "    token2id, id2token = build_vocab(all_train_tokens)\n",
    "    train_data_indices = token2index_dataset(train_data_tokens)\n",
    "    val_data_indices = token2index_dataset(val_data_tokens)\n",
    "    test_data_indices = token2index_dataset(test_data_tokens)\n",
    "    \n",
    "    # create dataloader\n",
    "    train_dataset = NewsGroupDataset(train_data_indices, train_label)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               collate_fn=newsgroup_collate_func,\n",
    "                                               shuffle=True)\n",
    "\n",
    "    val_dataset = NewsGroupDataset(val_data_indices, val_label)\n",
    "    val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               collate_fn=newsgroup_collate_func,\n",
    "                                               shuffle=True)\n",
    "\n",
    "    test_dataset = NewsGroupDataset(test_data_indices, test_label)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               collate_fn=newsgroup_collate_func,\n",
    "                                               shuffle=False)\n",
    "    # run models\n",
    "    model = BagOfWords(len(id2token), emb_dim)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (data, lengths, labels) in enumerate(train_loader):\n",
    "            model.train()\n",
    "            data_batch, length_batch, label_batch = data, lengths, labels\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data_batch, length_batch)\n",
    "            loss = criterion(outputs, label_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # validate every 300 iterations\n",
    "            if i > 0 and i % 300 == 0:\n",
    "                # validate\n",
    "                val_acc = test_model(val_loader, model)\n",
    "                print('Epoch: [{}/{}], Step: [{}/{}], Validation Acc: {}'.format( \n",
    "                           epoch+1, num_epochs, i+1, len(train_loader), val_acc))\n",
    "    \n",
    "    print('Vocab Size: {}, Validation Acc: {}'.format( \n",
    "                       size, test_model(val_loader, model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test maximum sentence length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "max_vocab_size = 50000\n",
    "BATCH_SIZE = 32\n",
    "learning_rate = 0.01\n",
    "num_epochs = 10\n",
    "emb_dim = 100 # bigger is better, 200, 500...\n",
    "criterion = torch.nn.CrossEntropyLoss()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENTENCE_LENGTH = [300, 400, 500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/10], Step: [301/625], Validation Acc: 86.06\n",
      "Epoch: [1/10], Step: [601/625], Validation Acc: 88.62\n",
      "Epoch: [2/10], Step: [301/625], Validation Acc: 88.28\n",
      "Epoch: [2/10], Step: [601/625], Validation Acc: 88.74\n",
      "Epoch: [3/10], Step: [301/625], Validation Acc: 88.18\n",
      "Epoch: [3/10], Step: [601/625], Validation Acc: 88.48\n",
      "Epoch: [4/10], Step: [301/625], Validation Acc: 88.22\n",
      "Epoch: [4/10], Step: [601/625], Validation Acc: 88.1\n",
      "Epoch: [5/10], Step: [301/625], Validation Acc: 88.12\n",
      "Epoch: [5/10], Step: [601/625], Validation Acc: 88.06\n",
      "Epoch: [6/10], Step: [301/625], Validation Acc: 88.12\n",
      "Epoch: [6/10], Step: [601/625], Validation Acc: 88.16\n",
      "Epoch: [7/10], Step: [301/625], Validation Acc: 88.14\n",
      "Epoch: [7/10], Step: [601/625], Validation Acc: 88.14\n",
      "Epoch: [8/10], Step: [301/625], Validation Acc: 88.16\n",
      "Epoch: [8/10], Step: [601/625], Validation Acc: 88.1\n",
      "Epoch: [9/10], Step: [301/625], Validation Acc: 88.2\n",
      "Epoch: [9/10], Step: [601/625], Validation Acc: 88.14\n",
      "Epoch: [10/10], Step: [301/625], Validation Acc: 88.18\n",
      "Epoch: [10/10], Step: [601/625], Validation Acc: 88.16\n",
      "Sentence length: 300, Validation Acc: 88.26\n",
      "Epoch: [1/10], Step: [301/625], Validation Acc: 87.64\n",
      "Epoch: [1/10], Step: [601/625], Validation Acc: 89.12\n",
      "Epoch: [2/10], Step: [301/625], Validation Acc: 89.72\n",
      "Epoch: [2/10], Step: [601/625], Validation Acc: 89.14\n",
      "Epoch: [3/10], Step: [301/625], Validation Acc: 89.62\n",
      "Epoch: [3/10], Step: [601/625], Validation Acc: 88.58\n",
      "Epoch: [4/10], Step: [301/625], Validation Acc: 89.5\n",
      "Epoch: [4/10], Step: [601/625], Validation Acc: 89.36\n",
      "Epoch: [5/10], Step: [301/625], Validation Acc: 89.46\n",
      "Epoch: [5/10], Step: [601/625], Validation Acc: 89.32\n",
      "Epoch: [6/10], Step: [301/625], Validation Acc: 89.2\n",
      "Epoch: [6/10], Step: [601/625], Validation Acc: 89.3\n",
      "Epoch: [7/10], Step: [301/625], Validation Acc: 89.3\n",
      "Epoch: [7/10], Step: [601/625], Validation Acc: 89.2\n",
      "Epoch: [8/10], Step: [301/625], Validation Acc: 89.22\n",
      "Epoch: [8/10], Step: [601/625], Validation Acc: 89.14\n",
      "Epoch: [9/10], Step: [301/625], Validation Acc: 89.16\n",
      "Epoch: [9/10], Step: [601/625], Validation Acc: 89.12\n",
      "Epoch: [10/10], Step: [301/625], Validation Acc: 89.1\n",
      "Epoch: [10/10], Step: [601/625], Validation Acc: 89.0\n",
      "Sentence length: 400, Validation Acc: 88.98\n",
      "Epoch: [1/10], Step: [301/625], Validation Acc: 87.56\n",
      "Epoch: [1/10], Step: [601/625], Validation Acc: 88.84\n",
      "Epoch: [2/10], Step: [301/625], Validation Acc: 90.38\n",
      "Epoch: [2/10], Step: [601/625], Validation Acc: 89.6\n",
      "Epoch: [3/10], Step: [301/625], Validation Acc: 89.88\n",
      "Epoch: [3/10], Step: [601/625], Validation Acc: 89.54\n",
      "Epoch: [4/10], Step: [301/625], Validation Acc: 89.9\n",
      "Epoch: [4/10], Step: [601/625], Validation Acc: 89.74\n",
      "Epoch: [5/10], Step: [301/625], Validation Acc: 89.6\n",
      "Epoch: [5/10], Step: [601/625], Validation Acc: 89.8\n",
      "Epoch: [6/10], Step: [301/625], Validation Acc: 89.64\n",
      "Epoch: [6/10], Step: [601/625], Validation Acc: 89.52\n",
      "Epoch: [7/10], Step: [301/625], Validation Acc: 89.8\n",
      "Epoch: [7/10], Step: [601/625], Validation Acc: 89.88\n",
      "Epoch: [8/10], Step: [301/625], Validation Acc: 89.84\n",
      "Epoch: [8/10], Step: [601/625], Validation Acc: 89.82\n",
      "Epoch: [9/10], Step: [301/625], Validation Acc: 89.88\n",
      "Epoch: [9/10], Step: [601/625], Validation Acc: 89.82\n",
      "Epoch: [10/10], Step: [301/625], Validation Acc: 89.8\n",
      "Epoch: [10/10], Step: [601/625], Validation Acc: 89.88\n",
      "Sentence length: 500, Validation Acc: 89.86\n"
     ]
    }
   ],
   "source": [
    "for sentence_length in MAX_SENTENCE_LENGTH:\n",
    "    MAX_SENTENCE_LENGTH = sentence_length\n",
    "    token2id, id2token = build_vocab(all_train_tokens)\n",
    "    train_data_indices = token2index_dataset(train_data_tokens)\n",
    "    val_data_indices = token2index_dataset(val_data_tokens)\n",
    "    test_data_indices = token2index_dataset(test_data_tokens)\n",
    "    \n",
    "    # create dataloader\n",
    "    train_dataset = NewsGroupDataset(train_data_indices, train_label)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               collate_fn=newsgroup_collate_func,\n",
    "                                               shuffle=True)\n",
    "\n",
    "    val_dataset = NewsGroupDataset(val_data_indices, val_label)\n",
    "    val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               collate_fn=newsgroup_collate_func,\n",
    "                                               shuffle=True)\n",
    "\n",
    "    test_dataset = NewsGroupDataset(test_data_indices, test_label)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               collate_fn=newsgroup_collate_func,\n",
    "                                               shuffle=False)\n",
    "    # run models\n",
    "    model = BagOfWords(len(id2token), emb_dim)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (data, lengths, labels) in enumerate(train_loader):\n",
    "            model.train()\n",
    "            data_batch, length_batch, label_batch = data, lengths, labels\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data_batch, length_batch)\n",
    "            loss = criterion(outputs, label_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # validate every 300 iterations\n",
    "            if i > 0 and i % 300 == 0:\n",
    "                # validate\n",
    "                val_acc = test_model(val_loader, model)\n",
    "                print('Epoch: [{}/{}], Step: [{}/{}], Validation Acc: {}'.format( \n",
    "                           epoch+1, num_epochs, i+1, len(train_loader), val_acc))\n",
    "    \n",
    "    print('Sentence length: {}, Validation Acc: {}'.format( \n",
    "                       sentence_length, test_model(val_loader, model)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SENTENCE_LENGTH = [600, 700, 800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/10], Step: [301/625], Validation Acc: 88.36\n",
      "Epoch: [1/10], Step: [601/625], Validation Acc: 90.18\n",
      "Epoch: [2/10], Step: [301/625], Validation Acc: 90.44\n",
      "Epoch: [2/10], Step: [601/625], Validation Acc: 89.9\n",
      "Epoch: [3/10], Step: [301/625], Validation Acc: 90.52\n",
      "Epoch: [3/10], Step: [601/625], Validation Acc: 89.76\n",
      "Epoch: [4/10], Step: [301/625], Validation Acc: 90.16\n",
      "Epoch: [4/10], Step: [601/625], Validation Acc: 90.2\n",
      "Epoch: [5/10], Step: [301/625], Validation Acc: 89.74\n",
      "Epoch: [5/10], Step: [601/625], Validation Acc: 90.24\n",
      "Epoch: [6/10], Step: [301/625], Validation Acc: 90.36\n",
      "Epoch: [6/10], Step: [601/625], Validation Acc: 90.3\n",
      "Epoch: [7/10], Step: [301/625], Validation Acc: 90.24\n",
      "Epoch: [7/10], Step: [601/625], Validation Acc: 90.2\n",
      "Epoch: [8/10], Step: [301/625], Validation Acc: 90.12\n",
      "Epoch: [8/10], Step: [601/625], Validation Acc: 90.2\n",
      "Epoch: [9/10], Step: [301/625], Validation Acc: 90.34\n",
      "Epoch: [9/10], Step: [601/625], Validation Acc: 90.2\n",
      "Epoch: [10/10], Step: [301/625], Validation Acc: 90.14\n",
      "Epoch: [10/10], Step: [601/625], Validation Acc: 90.12\n",
      "Sentence length: 600, Validation Acc: 90.06\n",
      "Epoch: [1/10], Step: [301/625], Validation Acc: 85.96\n",
      "Epoch: [1/10], Step: [601/625], Validation Acc: 90.2\n",
      "Epoch: [2/10], Step: [301/625], Validation Acc: 90.78\n",
      "Epoch: [2/10], Step: [601/625], Validation Acc: 90.52\n",
      "Epoch: [3/10], Step: [301/625], Validation Acc: 90.7\n",
      "Epoch: [3/10], Step: [601/625], Validation Acc: 89.9\n",
      "Epoch: [4/10], Step: [301/625], Validation Acc: 90.62\n",
      "Epoch: [4/10], Step: [601/625], Validation Acc: 90.3\n",
      "Epoch: [5/10], Step: [301/625], Validation Acc: 90.5\n",
      "Epoch: [5/10], Step: [601/625], Validation Acc: 90.42\n",
      "Epoch: [6/10], Step: [301/625], Validation Acc: 90.56\n",
      "Epoch: [6/10], Step: [601/625], Validation Acc: 90.46\n",
      "Epoch: [7/10], Step: [301/625], Validation Acc: 90.4\n",
      "Epoch: [7/10], Step: [601/625], Validation Acc: 90.42\n",
      "Epoch: [8/10], Step: [301/625], Validation Acc: 90.38\n",
      "Epoch: [8/10], Step: [601/625], Validation Acc: 90.5\n",
      "Epoch: [9/10], Step: [301/625], Validation Acc: 90.4\n",
      "Epoch: [9/10], Step: [601/625], Validation Acc: 90.26\n",
      "Epoch: [10/10], Step: [301/625], Validation Acc: 90.46\n",
      "Epoch: [10/10], Step: [601/625], Validation Acc: 90.28\n",
      "Sentence length: 700, Validation Acc: 90.44\n",
      "Epoch: [1/10], Step: [301/625], Validation Acc: 87.94\n",
      "Epoch: [1/10], Step: [601/625], Validation Acc: 89.46\n",
      "Epoch: [2/10], Step: [301/625], Validation Acc: 90.0\n",
      "Epoch: [2/10], Step: [601/625], Validation Acc: 90.1\n",
      "Epoch: [3/10], Step: [301/625], Validation Acc: 90.58\n",
      "Epoch: [3/10], Step: [601/625], Validation Acc: 89.7\n",
      "Epoch: [4/10], Step: [301/625], Validation Acc: 90.54\n",
      "Epoch: [4/10], Step: [601/625], Validation Acc: 90.42\n",
      "Epoch: [5/10], Step: [301/625], Validation Acc: 90.5\n",
      "Epoch: [5/10], Step: [601/625], Validation Acc: 90.6\n",
      "Epoch: [6/10], Step: [301/625], Validation Acc: 90.5\n",
      "Epoch: [6/10], Step: [601/625], Validation Acc: 90.56\n",
      "Epoch: [7/10], Step: [301/625], Validation Acc: 90.44\n",
      "Epoch: [7/10], Step: [601/625], Validation Acc: 90.68\n",
      "Epoch: [8/10], Step: [301/625], Validation Acc: 90.62\n",
      "Epoch: [8/10], Step: [601/625], Validation Acc: 90.62\n",
      "Epoch: [9/10], Step: [301/625], Validation Acc: 90.54\n",
      "Epoch: [9/10], Step: [601/625], Validation Acc: 90.54\n",
      "Epoch: [10/10], Step: [301/625], Validation Acc: 90.56\n",
      "Epoch: [10/10], Step: [601/625], Validation Acc: 90.58\n",
      "Sentence length: 800, Validation Acc: 90.6\n"
     ]
    }
   ],
   "source": [
    "for sentence_length in MAX_SENTENCE_LENGTH:\n",
    "    MAX_SENTENCE_LENGTH = sentence_length\n",
    "    token2id, id2token = build_vocab(all_train_tokens)\n",
    "    train_data_indices = token2index_dataset(train_data_tokens)\n",
    "    val_data_indices = token2index_dataset(val_data_tokens)\n",
    "    test_data_indices = token2index_dataset(test_data_tokens)\n",
    "    \n",
    "    # create dataloader\n",
    "    train_dataset = NewsGroupDataset(train_data_indices, train_label)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               collate_fn=newsgroup_collate_func,\n",
    "                                               shuffle=True)\n",
    "\n",
    "    val_dataset = NewsGroupDataset(val_data_indices, val_label)\n",
    "    val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               collate_fn=newsgroup_collate_func,\n",
    "                                               shuffle=True)\n",
    "\n",
    "    test_dataset = NewsGroupDataset(test_data_indices, test_label)\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               collate_fn=newsgroup_collate_func,\n",
    "                                               shuffle=False)\n",
    "    # run models\n",
    "    model = BagOfWords(len(id2token), emb_dim)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (data, lengths, labels) in enumerate(train_loader):\n",
    "            model.train()\n",
    "            data_batch, length_batch, label_batch = data, lengths, labels\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data_batch, length_batch)\n",
    "            loss = criterion(outputs, label_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # validate every 300 iterations\n",
    "            if i > 0 and i % 300 == 0:\n",
    "                # validate\n",
    "                val_acc = test_model(val_loader, model)\n",
    "                print('Epoch: [{}/{}], Step: [{}/{}], Validation Acc: {}'.format( \n",
    "                           epoch+1, num_epochs, i+1, len(train_loader), val_acc))\n",
    "    \n",
    "    print('Sentence length: {}, Validation Acc: {}'.format( \n",
    "                       sentence_length, test_model(val_loader, model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test of embedding size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "max_vocab_size = 50000\n",
    "MAX_SENTENCE_LENGTH = 800\n",
    "BATCH_SIZE = 32\n",
    "learning_rate = 0.01\n",
    "num_epochs = 10\n",
    "criterion = torch.nn.CrossEntropyLoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "try_emb_dim = [200, 500, 1000]\n",
    "token2id, id2token = build_vocab(all_train_tokens)\n",
    "train_data_indices = token2index_dataset(train_data_tokens)\n",
    "val_data_indices = token2index_dataset(val_data_tokens)\n",
    "test_data_indices = token2index_dataset(test_data_tokens)\n",
    "    \n",
    "# create dataloader\n",
    "train_dataset = NewsGroupDataset(train_data_indices, train_label)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                            batch_size=BATCH_SIZE,\n",
    "                                            collate_fn=newsgroup_collate_func,\n",
    "                                            shuffle=True)\n",
    "\n",
    "val_dataset = NewsGroupDataset(val_data_indices, val_label)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                            batch_size=BATCH_SIZE,\n",
    "                                            collate_fn=newsgroup_collate_func,\n",
    "                                            shuffle=True)\n",
    "\n",
    "test_dataset = NewsGroupDataset(test_data_indices, test_label)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                            batch_size=BATCH_SIZE,\n",
    "                                            collate_fn=newsgroup_collate_func,\n",
    "                                            shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/10], Step: [301/625], Validation Acc: 88.92\n",
      "Epoch: [1/10], Step: [601/625], Validation Acc: 90.76\n",
      "Epoch: [2/10], Step: [301/625], Validation Acc: 90.96\n",
      "Epoch: [2/10], Step: [601/625], Validation Acc: 90.22\n",
      "Epoch: [3/10], Step: [301/625], Validation Acc: 90.46\n",
      "Epoch: [3/10], Step: [601/625], Validation Acc: 90.6\n",
      "Epoch: [4/10], Step: [301/625], Validation Acc: 90.46\n",
      "Epoch: [4/10], Step: [601/625], Validation Acc: 90.56\n",
      "Epoch: [5/10], Step: [301/625], Validation Acc: 90.52\n",
      "Epoch: [5/10], Step: [601/625], Validation Acc: 90.32\n",
      "Epoch: [6/10], Step: [301/625], Validation Acc: 90.6\n",
      "Epoch: [6/10], Step: [601/625], Validation Acc: 90.54\n",
      "Epoch: [7/10], Step: [301/625], Validation Acc: 90.54\n",
      "Epoch: [7/10], Step: [601/625], Validation Acc: 90.66\n",
      "Epoch: [8/10], Step: [301/625], Validation Acc: 90.66\n",
      "Epoch: [8/10], Step: [601/625], Validation Acc: 90.7\n",
      "Epoch: [9/10], Step: [301/625], Validation Acc: 90.62\n",
      "Epoch: [9/10], Step: [601/625], Validation Acc: 90.62\n",
      "Epoch: [10/10], Step: [301/625], Validation Acc: 90.7\n",
      "Epoch: [10/10], Step: [601/625], Validation Acc: 90.58\n",
      "Embedding dimension: 200, Validation Acc: 90.48\n",
      "Epoch: [1/10], Step: [301/625], Validation Acc: 89.44\n",
      "Epoch: [1/10], Step: [601/625], Validation Acc: 90.06\n",
      "Epoch: [2/10], Step: [301/625], Validation Acc: 89.68\n",
      "Epoch: [2/10], Step: [601/625], Validation Acc: 89.46\n",
      "Epoch: [3/10], Step: [301/625], Validation Acc: 90.1\n",
      "Epoch: [3/10], Step: [601/625], Validation Acc: 89.88\n",
      "Epoch: [4/10], Step: [301/625], Validation Acc: 90.36\n",
      "Epoch: [4/10], Step: [601/625], Validation Acc: 90.3\n",
      "Epoch: [5/10], Step: [301/625], Validation Acc: 90.2\n",
      "Epoch: [5/10], Step: [601/625], Validation Acc: 90.3\n",
      "Epoch: [6/10], Step: [301/625], Validation Acc: 90.28\n",
      "Epoch: [6/10], Step: [601/625], Validation Acc: 90.2\n",
      "Epoch: [7/10], Step: [301/625], Validation Acc: 90.32\n",
      "Epoch: [7/10], Step: [601/625], Validation Acc: 90.32\n",
      "Epoch: [8/10], Step: [301/625], Validation Acc: 90.04\n",
      "Epoch: [8/10], Step: [601/625], Validation Acc: 89.8\n",
      "Epoch: [9/10], Step: [301/625], Validation Acc: 89.96\n",
      "Epoch: [9/10], Step: [601/625], Validation Acc: 89.98\n",
      "Epoch: [10/10], Step: [301/625], Validation Acc: 89.96\n",
      "Epoch: [10/10], Step: [601/625], Validation Acc: 89.94\n",
      "Embedding dimension: 500, Validation Acc: 90.12\n",
      "Epoch: [1/10], Step: [301/625], Validation Acc: 88.96\n",
      "Epoch: [1/10], Step: [601/625], Validation Acc: 89.24\n",
      "Epoch: [2/10], Step: [301/625], Validation Acc: 90.46\n",
      "Epoch: [2/10], Step: [601/625], Validation Acc: 89.76\n",
      "Epoch: [3/10], Step: [301/625], Validation Acc: 89.22\n",
      "Epoch: [3/10], Step: [601/625], Validation Acc: 89.42\n",
      "Epoch: [4/10], Step: [301/625], Validation Acc: 90.0\n",
      "Epoch: [4/10], Step: [601/625], Validation Acc: 89.98\n",
      "Epoch: [5/10], Step: [301/625], Validation Acc: 90.16\n",
      "Epoch: [5/10], Step: [601/625], Validation Acc: 90.18\n",
      "Epoch: [6/10], Step: [301/625], Validation Acc: 90.16\n",
      "Epoch: [6/10], Step: [601/625], Validation Acc: 90.28\n",
      "Epoch: [7/10], Step: [301/625], Validation Acc: 90.14\n",
      "Epoch: [7/10], Step: [601/625], Validation Acc: 90.18\n",
      "Epoch: [8/10], Step: [301/625], Validation Acc: 90.24\n",
      "Epoch: [8/10], Step: [601/625], Validation Acc: 90.22\n",
      "Epoch: [9/10], Step: [301/625], Validation Acc: 90.2\n",
      "Epoch: [9/10], Step: [601/625], Validation Acc: 90.16\n",
      "Epoch: [10/10], Step: [301/625], Validation Acc: 90.18\n",
      "Epoch: [10/10], Step: [601/625], Validation Acc: 90.24\n",
      "Embedding dimension: 1000, Validation Acc: 90.14\n"
     ]
    }
   ],
   "source": [
    "for emb_dim in try_emb_dim:\n",
    "    model = BagOfWords(len(id2token), emb_dim)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (data, lengths, labels) in enumerate(train_loader):\n",
    "            model.train()\n",
    "            data_batch, length_batch, label_batch = data, lengths, labels\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data_batch, length_batch)\n",
    "            loss = criterion(outputs, label_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # validate every 300 iterations\n",
    "            if i > 0 and i % 300 == 0:\n",
    "                # validate\n",
    "                val_acc = test_model(val_loader, model)\n",
    "                print('Epoch: [{}/{}], Step: [{}/{}], Validation Acc: {}'.format( \n",
    "                           epoch+1, num_epochs, i+1, len(train_loader), val_acc))\n",
    "    \n",
    "    print('Embedding dimension: {}, Validation Acc: {}'.format( \n",
    "                       emb_dim, test_model(val_loader, model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test different optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "max_vocab_size = 50000\n",
    "MAX_SENTENCE_LENGTH = 800\n",
    "emb_dim = 200\n",
    "BATCH_SIZE = 32\n",
    "learning_rate = 0.01\n",
    "num_epochs = 10\n",
    "criterion = torch.nn.CrossEntropyLoss() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/10], Step: [301/625], Validation Acc: 52.2\n",
      "Epoch: [1/10], Step: [601/625], Validation Acc: 54.36\n",
      "Optimizer: SGD, Validation Acc: 56.8\n",
      "Epoch: [2/10], Step: [301/625], Validation Acc: 51.82\n",
      "Epoch: [2/10], Step: [601/625], Validation Acc: 60.66\n",
      "Optimizer: SGD, Validation Acc: 62.24\n",
      "Epoch: [3/10], Step: [301/625], Validation Acc: 54.06\n",
      "Epoch: [3/10], Step: [601/625], Validation Acc: 61.54\n",
      "Optimizer: SGD, Validation Acc: 60.68\n",
      "Epoch: [4/10], Step: [301/625], Validation Acc: 53.54\n",
      "Epoch: [4/10], Step: [601/625], Validation Acc: 62.2\n",
      "Optimizer: SGD, Validation Acc: 52.96\n",
      "Epoch: [5/10], Step: [301/625], Validation Acc: 60.04\n",
      "Epoch: [5/10], Step: [601/625], Validation Acc: 56.56\n",
      "Optimizer: SGD, Validation Acc: 63.14\n",
      "Epoch: [6/10], Step: [301/625], Validation Acc: 62.14\n",
      "Epoch: [6/10], Step: [601/625], Validation Acc: 62.4\n",
      "Optimizer: SGD, Validation Acc: 52.14\n",
      "Epoch: [7/10], Step: [301/625], Validation Acc: 62.94\n",
      "Epoch: [7/10], Step: [601/625], Validation Acc: 60.42\n",
      "Optimizer: SGD, Validation Acc: 65.2\n",
      "Epoch: [8/10], Step: [301/625], Validation Acc: 53.1\n",
      "Epoch: [8/10], Step: [601/625], Validation Acc: 63.34\n",
      "Optimizer: SGD, Validation Acc: 64.74\n",
      "Epoch: [9/10], Step: [301/625], Validation Acc: 58.24\n",
      "Epoch: [9/10], Step: [601/625], Validation Acc: 59.84\n",
      "Optimizer: SGD, Validation Acc: 63.6\n",
      "Epoch: [10/10], Step: [301/625], Validation Acc: 64.46\n",
      "Epoch: [10/10], Step: [601/625], Validation Acc: 63.3\n",
      "Optimizer: SGD, Validation Acc: 65.66\n"
     ]
    }
   ],
   "source": [
    "model = BagOfWords(len(id2token), emb_dim)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (data, lengths, labels) in enumerate(train_loader):\n",
    "        model.train()\n",
    "        data_batch, length_batch, label_batch = data, lengths, labels\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data_batch, length_batch)\n",
    "        loss = criterion(outputs, label_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # validate every 300 iterations\n",
    "        if i > 0 and i % 300 == 0:\n",
    "            # validate\n",
    "            val_acc = test_model(val_loader, model)\n",
    "            print('Epoch: [{}/{}], Step: [{}/{}], Validation Acc: {}'.format( \n",
    "                        epoch+1, num_epochs, i+1, len(train_loader), val_acc))\n",
    "    \n",
    "    print('Optimizer: SGD, Validation Acc: {}'.format( \n",
    "                       test_model(val_loader, model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test of learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "max_vocab_size = 50000\n",
    "MAX_SENTENCE_LENGTH = 800\n",
    "emb_dim = 200\n",
    "BATCH_SIZE = 32\n",
    "learning_rate = 0.01\n",
    "num_epochs = 10\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "model = BagOfWords(len(id2token), emb_dim)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "try_learning_rate = [0.0001, 0.001, 0.005, 0.01, 0.05]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/10], Step: [301/625], Validation Acc: 50.02\n",
      "Epoch: [1/10], Step: [601/625], Validation Acc: 51.52\n",
      "Epoch: [2/10], Step: [301/625], Validation Acc: 62.82\n",
      "Epoch: [2/10], Step: [601/625], Validation Acc: 58.24\n",
      "Epoch: [3/10], Step: [301/625], Validation Acc: 62.28\n",
      "Epoch: [3/10], Step: [601/625], Validation Acc: 59.72\n",
      "Epoch: [4/10], Step: [301/625], Validation Acc: 74.72\n",
      "Epoch: [4/10], Step: [601/625], Validation Acc: 59.68\n",
      "Epoch: [5/10], Step: [301/625], Validation Acc: 63.94\n",
      "Epoch: [5/10], Step: [601/625], Validation Acc: 77.16\n",
      "Epoch: [6/10], Step: [301/625], Validation Acc: 72.0\n",
      "Epoch: [6/10], Step: [601/625], Validation Acc: 76.68\n",
      "Epoch: [7/10], Step: [301/625], Validation Acc: 78.76\n",
      "Epoch: [7/10], Step: [601/625], Validation Acc: 79.2\n",
      "Epoch: [8/10], Step: [301/625], Validation Acc: 76.96\n",
      "Epoch: [8/10], Step: [601/625], Validation Acc: 80.24\n",
      "Epoch: [9/10], Step: [301/625], Validation Acc: 79.88\n",
      "Epoch: [9/10], Step: [601/625], Validation Acc: 80.1\n",
      "Epoch: [10/10], Step: [301/625], Validation Acc: 81.64\n",
      "Epoch: [10/10], Step: [601/625], Validation Acc: 81.64\n",
      "Learning rate: 0.0001, Validation Acc: 82.02\n",
      "Epoch: [1/10], Step: [301/625], Validation Acc: 75.18\n",
      "Epoch: [1/10], Step: [601/625], Validation Acc: 78.8\n",
      "Epoch: [2/10], Step: [301/625], Validation Acc: 85.34\n",
      "Epoch: [2/10], Step: [601/625], Validation Acc: 86.8\n",
      "Epoch: [3/10], Step: [301/625], Validation Acc: 87.74\n",
      "Epoch: [3/10], Step: [601/625], Validation Acc: 88.78\n",
      "Epoch: [4/10], Step: [301/625], Validation Acc: 89.5\n",
      "Epoch: [4/10], Step: [601/625], Validation Acc: 89.76\n",
      "Epoch: [5/10], Step: [301/625], Validation Acc: 89.92\n",
      "Epoch: [5/10], Step: [601/625], Validation Acc: 90.16\n",
      "Epoch: [6/10], Step: [301/625], Validation Acc: 90.38\n",
      "Epoch: [6/10], Step: [601/625], Validation Acc: 90.66\n",
      "Epoch: [7/10], Step: [301/625], Validation Acc: 90.58\n",
      "Epoch: [7/10], Step: [601/625], Validation Acc: 90.98\n",
      "Epoch: [8/10], Step: [301/625], Validation Acc: 91.0\n",
      "Epoch: [8/10], Step: [601/625], Validation Acc: 90.42\n",
      "Epoch: [9/10], Step: [301/625], Validation Acc: 91.12\n",
      "Epoch: [9/10], Step: [601/625], Validation Acc: 90.74\n",
      "Epoch: [10/10], Step: [301/625], Validation Acc: 91.0\n",
      "Epoch: [10/10], Step: [601/625], Validation Acc: 91.14\n",
      "Learning rate: 0.001, Validation Acc: 90.78\n",
      "Epoch: [1/10], Step: [301/625], Validation Acc: 86.64\n",
      "Epoch: [1/10], Step: [601/625], Validation Acc: 89.2\n",
      "Epoch: [2/10], Step: [301/625], Validation Acc: 90.3\n",
      "Epoch: [2/10], Step: [601/625], Validation Acc: 91.16\n",
      "Epoch: [3/10], Step: [301/625], Validation Acc: 90.18\n",
      "Epoch: [3/10], Step: [601/625], Validation Acc: 90.46\n",
      "Epoch: [4/10], Step: [301/625], Validation Acc: 90.78\n",
      "Epoch: [4/10], Step: [601/625], Validation Acc: 90.84\n",
      "Epoch: [5/10], Step: [301/625], Validation Acc: 90.86\n",
      "Epoch: [5/10], Step: [601/625], Validation Acc: 90.72\n",
      "Epoch: [6/10], Step: [301/625], Validation Acc: 90.78\n",
      "Epoch: [6/10], Step: [601/625], Validation Acc: 90.74\n",
      "Epoch: [7/10], Step: [301/625], Validation Acc: 90.68\n",
      "Epoch: [7/10], Step: [601/625], Validation Acc: 90.68\n",
      "Epoch: [8/10], Step: [301/625], Validation Acc: 90.7\n",
      "Epoch: [8/10], Step: [601/625], Validation Acc: 90.66\n",
      "Epoch: [9/10], Step: [301/625], Validation Acc: 90.76\n",
      "Epoch: [9/10], Step: [601/625], Validation Acc: 90.52\n",
      "Epoch: [10/10], Step: [301/625], Validation Acc: 90.52\n",
      "Epoch: [10/10], Step: [601/625], Validation Acc: 90.74\n",
      "Learning rate: 0.005, Validation Acc: 90.48\n",
      "Epoch: [1/10], Step: [301/625], Validation Acc: 89.5\n",
      "Epoch: [1/10], Step: [601/625], Validation Acc: 90.26\n",
      "Epoch: [2/10], Step: [301/625], Validation Acc: 90.76\n",
      "Epoch: [2/10], Step: [601/625], Validation Acc: 90.54\n",
      "Epoch: [3/10], Step: [301/625], Validation Acc: 90.54\n",
      "Epoch: [3/10], Step: [601/625], Validation Acc: 89.38\n",
      "Epoch: [4/10], Step: [301/625], Validation Acc: 90.58\n",
      "Epoch: [4/10], Step: [601/625], Validation Acc: 90.46\n",
      "Epoch: [5/10], Step: [301/625], Validation Acc: 90.5\n",
      "Epoch: [5/10], Step: [601/625], Validation Acc: 90.48\n",
      "Epoch: [6/10], Step: [301/625], Validation Acc: 90.54\n",
      "Epoch: [6/10], Step: [601/625], Validation Acc: 90.56\n",
      "Epoch: [7/10], Step: [301/625], Validation Acc: 90.52\n",
      "Epoch: [7/10], Step: [601/625], Validation Acc: 90.56\n",
      "Epoch: [8/10], Step: [301/625], Validation Acc: 90.48\n",
      "Epoch: [8/10], Step: [601/625], Validation Acc: 90.48\n",
      "Epoch: [9/10], Step: [301/625], Validation Acc: 90.5\n",
      "Epoch: [9/10], Step: [601/625], Validation Acc: 90.46\n",
      "Epoch: [10/10], Step: [301/625], Validation Acc: 90.42\n",
      "Epoch: [10/10], Step: [601/625], Validation Acc: 90.48\n",
      "Learning rate: 0.01, Validation Acc: 90.46\n",
      "Epoch: [1/10], Step: [301/625], Validation Acc: 89.26\n",
      "Epoch: [1/10], Step: [601/625], Validation Acc: 90.24\n",
      "Epoch: [2/10], Step: [301/625], Validation Acc: 90.1\n",
      "Epoch: [2/10], Step: [601/625], Validation Acc: 89.58\n",
      "Epoch: [3/10], Step: [301/625], Validation Acc: 88.16\n",
      "Epoch: [3/10], Step: [601/625], Validation Acc: 88.76\n",
      "Epoch: [4/10], Step: [301/625], Validation Acc: 89.02\n",
      "Epoch: [4/10], Step: [601/625], Validation Acc: 89.44\n",
      "Epoch: [5/10], Step: [301/625], Validation Acc: 89.0\n",
      "Epoch: [5/10], Step: [601/625], Validation Acc: 88.84\n",
      "Epoch: [6/10], Step: [301/625], Validation Acc: 87.54\n",
      "Epoch: [6/10], Step: [601/625], Validation Acc: 87.86\n",
      "Epoch: [7/10], Step: [301/625], Validation Acc: 88.66\n",
      "Epoch: [7/10], Step: [601/625], Validation Acc: 88.54\n",
      "Epoch: [8/10], Step: [301/625], Validation Acc: 88.76\n",
      "Epoch: [8/10], Step: [601/625], Validation Acc: 88.02\n",
      "Epoch: [9/10], Step: [301/625], Validation Acc: 87.72\n",
      "Epoch: [9/10], Step: [601/625], Validation Acc: 86.44\n",
      "Epoch: [10/10], Step: [301/625], Validation Acc: 87.92\n",
      "Epoch: [10/10], Step: [601/625], Validation Acc: 88.52\n",
      "Learning rate: 0.05, Validation Acc: 88.66\n"
     ]
    }
   ],
   "source": [
    "for learning_rate in try_learning_rate:\n",
    "    model = BagOfWords(len(id2token), emb_dim)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (data, lengths, labels) in enumerate(train_loader):\n",
    "            model.train()\n",
    "            data_batch, length_batch, label_batch = data, lengths, labels\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(data_batch, length_batch)\n",
    "            loss = criterion(outputs, label_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # validate every 300 iterations\n",
    "            if i > 0 and i % 300 == 0:\n",
    "                # validate\n",
    "                val_acc = test_model(val_loader, model)\n",
    "                print('Epoch: [{}/{}], Step: [{}/{}], Validation Acc: {}'.format( \n",
    "                           epoch+1, num_epochs, i+1, len(train_loader), val_acc))\n",
    "    \n",
    "    print('Learning rate: {}, Validation Acc: {}'.format( \n",
    "                       learning_rate, test_model(val_loader, model)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run anealing learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "max_vocab_size = 50000\n",
    "MAX_SENTENCE_LENGTH = 800\n",
    "emb_dim = 200\n",
    "BATCH_SIZE = 32\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "model = BagOfWords(len(id2token), emb_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/30], Step: [301/625], Validation Acc: 58.06\n",
      "Epoch: [1/30], Step: [601/625], Validation Acc: 73.62\n",
      "Learning rate: 0.005, Validation Acc: 76.5\n",
      "Epoch: [2/30], Step: [301/625], Validation Acc: 81.46\n",
      "Epoch: [2/30], Step: [601/625], Validation Acc: 81.74\n",
      "Learning rate: 0.005, Validation Acc: 83.78\n",
      "Epoch: [3/30], Step: [301/625], Validation Acc: 84.52\n",
      "Epoch: [3/30], Step: [601/625], Validation Acc: 85.1\n",
      "Learning rate: 0.005, Validation Acc: 84.1\n",
      "Epoch: [4/30], Step: [301/625], Validation Acc: 85.12\n",
      "Epoch: [4/30], Step: [601/625], Validation Acc: 85.7\n",
      "Learning rate: 0.0025, Validation Acc: 85.96\n",
      "Epoch: [5/30], Step: [301/625], Validation Acc: 86.1\n",
      "Epoch: [5/30], Step: [601/625], Validation Acc: 86.24\n",
      "Learning rate: 0.0025, Validation Acc: 86.52\n",
      "Epoch: [6/30], Step: [301/625], Validation Acc: 85.76\n",
      "Epoch: [6/30], Step: [601/625], Validation Acc: 86.46\n",
      "Learning rate: 0.0025, Validation Acc: 86.54\n",
      "Epoch: [7/30], Step: [301/625], Validation Acc: 85.64\n",
      "Epoch: [7/30], Step: [601/625], Validation Acc: 86.72\n",
      "Learning rate: 0.00125, Validation Acc: 86.56\n",
      "Epoch: [8/30], Step: [301/625], Validation Acc: 85.78\n",
      "Epoch: [8/30], Step: [601/625], Validation Acc: 86.84\n",
      "Learning rate: 0.00125, Validation Acc: 86.72\n",
      "Epoch: [9/30], Step: [301/625], Validation Acc: 85.86\n",
      "Epoch: [9/30], Step: [601/625], Validation Acc: 87.24\n",
      "Learning rate: 0.00125, Validation Acc: 87.26\n",
      "Epoch: [10/30], Step: [301/625], Validation Acc: 87.18\n",
      "Epoch: [10/30], Step: [601/625], Validation Acc: 87.26\n",
      "Learning rate: 0.000625, Validation Acc: 87.02\n",
      "Epoch: [11/30], Step: [301/625], Validation Acc: 87.14\n",
      "Epoch: [11/30], Step: [601/625], Validation Acc: 87.28\n",
      "Learning rate: 0.000625, Validation Acc: 87.36\n",
      "Epoch: [12/30], Step: [301/625], Validation Acc: 87.04\n",
      "Epoch: [12/30], Step: [601/625], Validation Acc: 87.4\n",
      "Learning rate: 0.000625, Validation Acc: 86.9\n",
      "Epoch: [13/30], Step: [301/625], Validation Acc: 87.28\n",
      "Epoch: [13/30], Step: [601/625], Validation Acc: 87.26\n",
      "Learning rate: 0.0003125, Validation Acc: 87.22\n",
      "Epoch: [14/30], Step: [301/625], Validation Acc: 87.3\n",
      "Epoch: [14/30], Step: [601/625], Validation Acc: 87.26\n",
      "Learning rate: 0.0003125, Validation Acc: 87.34\n",
      "Epoch: [15/30], Step: [301/625], Validation Acc: 87.26\n",
      "Epoch: [15/30], Step: [601/625], Validation Acc: 87.38\n",
      "Learning rate: 0.0003125, Validation Acc: 87.04\n",
      "Epoch: [16/30], Step: [301/625], Validation Acc: 87.36\n",
      "Epoch: [16/30], Step: [601/625], Validation Acc: 87.38\n",
      "Learning rate: 0.00015625, Validation Acc: 87.36\n",
      "Epoch: [17/30], Step: [301/625], Validation Acc: 87.2\n",
      "Epoch: [17/30], Step: [601/625], Validation Acc: 87.5\n",
      "Learning rate: 0.00015625, Validation Acc: 87.4\n",
      "Epoch: [18/30], Step: [301/625], Validation Acc: 87.3\n",
      "Epoch: [18/30], Step: [601/625], Validation Acc: 87.42\n",
      "Learning rate: 0.00015625, Validation Acc: 87.42\n",
      "Epoch: [19/30], Step: [301/625], Validation Acc: 87.38\n",
      "Epoch: [19/30], Step: [601/625], Validation Acc: 87.42\n",
      "Learning rate: 7.8125e-05, Validation Acc: 87.44\n",
      "Epoch: [20/30], Step: [301/625], Validation Acc: 87.4\n",
      "Epoch: [20/30], Step: [601/625], Validation Acc: 87.32\n",
      "Learning rate: 7.8125e-05, Validation Acc: 87.46\n",
      "Epoch: [21/30], Step: [301/625], Validation Acc: 87.54\n",
      "Epoch: [21/30], Step: [601/625], Validation Acc: 87.48\n",
      "Learning rate: 7.8125e-05, Validation Acc: 87.4\n",
      "Epoch: [22/30], Step: [301/625], Validation Acc: 87.4\n",
      "Epoch: [22/30], Step: [601/625], Validation Acc: 87.36\n",
      "Learning rate: 3.90625e-05, Validation Acc: 87.44\n",
      "Epoch: [23/30], Step: [301/625], Validation Acc: 87.38\n",
      "Epoch: [23/30], Step: [601/625], Validation Acc: 87.5\n",
      "Learning rate: 3.90625e-05, Validation Acc: 87.4\n",
      "Epoch: [24/30], Step: [301/625], Validation Acc: 87.36\n",
      "Epoch: [24/30], Step: [601/625], Validation Acc: 87.36\n",
      "Learning rate: 3.90625e-05, Validation Acc: 87.46\n",
      "Epoch: [25/30], Step: [301/625], Validation Acc: 87.4\n",
      "Epoch: [25/30], Step: [601/625], Validation Acc: 87.32\n",
      "Learning rate: 1.953125e-05, Validation Acc: 87.34\n",
      "Epoch: [26/30], Step: [301/625], Validation Acc: 87.36\n",
      "Epoch: [26/30], Step: [601/625], Validation Acc: 87.5\n",
      "Learning rate: 1.953125e-05, Validation Acc: 87.5\n",
      "Epoch: [27/30], Step: [301/625], Validation Acc: 87.38\n",
      "Epoch: [27/30], Step: [601/625], Validation Acc: 87.5\n",
      "Learning rate: 1.953125e-05, Validation Acc: 87.48\n",
      "Epoch: [28/30], Step: [301/625], Validation Acc: 87.5\n",
      "Epoch: [28/30], Step: [601/625], Validation Acc: 87.4\n",
      "Learning rate: 9.765625e-06, Validation Acc: 87.38\n",
      "Epoch: [29/30], Step: [301/625], Validation Acc: 87.42\n",
      "Epoch: [29/30], Step: [601/625], Validation Acc: 87.5\n",
      "Learning rate: 9.765625e-06, Validation Acc: 87.52\n",
      "Epoch: [30/30], Step: [301/625], Validation Acc: 87.46\n",
      "Epoch: [30/30], Step: [601/625], Validation Acc: 87.42\n",
      "Learning rate: 9.765625e-06, Validation Acc: 87.38\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "learning_rate = 0.005\n",
    "train_accuracy_reg = []\n",
    "val_accuracy_reg = []\n",
    "for epoch in range(num_epochs):\n",
    "    if epoch > 0 and epoch % 3 == 0:\n",
    "        learning_rate = learning_rate / 2\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "    for i, (data, lengths, labels) in enumerate(train_loader):\n",
    "        model.train()\n",
    "        data_batch, length_batch, label_batch = data, lengths, labels\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data_batch, length_batch)\n",
    "        loss = criterion(outputs, label_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # validate every 300 iterations\n",
    "        if i > 0 and i % 300 == 0:\n",
    "            # validate\n",
    "            val_acc = test_model(val_loader, model)\n",
    "            print('Epoch: [{}/{}], Step: [{}/{}], Validation Acc: {}'.format( \n",
    "                        epoch+1, num_epochs, i+1, len(train_loader), val_acc))\n",
    "    trainacc = test_model(train_loader, model)\n",
    "    valacc = test_model(val_loader, model)\n",
    "    train_accuracy.append(trainacc)\n",
    "    val_accuracy.append(valacc)\n",
    "    print('Learning rate: {}, Validation Acc: {}'.format( \n",
    "                       learning_rate, valacc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(train_loader, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "without regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "max_vocab_size = 50000\n",
    "MAX_SENTENCE_LENGTH = 800\n",
    "emb_dim = 200\n",
    "BATCH_SIZE = 32\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "model = BagOfWords(len(id2token), emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/30], Step: [101/625], Validation Acc: 74.72\n",
      "Epoch: [1/30], Step: [201/625], Validation Acc: 83.18\n",
      "Epoch: [1/30], Step: [301/625], Validation Acc: 86.3\n",
      "Epoch: [1/30], Step: [401/625], Validation Acc: 82.74\n",
      "Epoch: [1/30], Step: [501/625], Validation Acc: 86.96\n",
      "Epoch: [1/30], Step: [601/625], Validation Acc: 89.62\n",
      "Learning rate: 0.005, Validation Acc: 89.7\n",
      "Epoch: [2/30], Step: [101/625], Validation Acc: 90.08\n",
      "Epoch: [2/30], Step: [201/625], Validation Acc: 90.18\n",
      "Epoch: [2/30], Step: [301/625], Validation Acc: 90.04\n",
      "Epoch: [2/30], Step: [401/625], Validation Acc: 88.28\n",
      "Epoch: [2/30], Step: [501/625], Validation Acc: 89.84\n",
      "Epoch: [2/30], Step: [601/625], Validation Acc: 90.44\n",
      "Learning rate: 0.005, Validation Acc: 90.78\n",
      "Epoch: [3/30], Step: [101/625], Validation Acc: 90.82\n",
      "Epoch: [3/30], Step: [201/625], Validation Acc: 90.62\n",
      "Epoch: [3/30], Step: [301/625], Validation Acc: 90.76\n",
      "Epoch: [3/30], Step: [401/625], Validation Acc: 90.8\n",
      "Epoch: [3/30], Step: [501/625], Validation Acc: 90.82\n",
      "Epoch: [3/30], Step: [601/625], Validation Acc: 90.82\n",
      "Learning rate: 0.005, Validation Acc: 88.88\n",
      "Epoch: [4/30], Step: [101/625], Validation Acc: 90.54\n",
      "Epoch: [4/30], Step: [201/625], Validation Acc: 90.86\n",
      "Epoch: [4/30], Step: [301/625], Validation Acc: 90.72\n",
      "Epoch: [4/30], Step: [401/625], Validation Acc: 91.06\n",
      "Epoch: [4/30], Step: [501/625], Validation Acc: 90.9\n",
      "Epoch: [4/30], Step: [601/625], Validation Acc: 90.86\n",
      "Learning rate: 0.0025, Validation Acc: 90.78\n",
      "Epoch: [5/30], Step: [101/625], Validation Acc: 90.78\n",
      "Epoch: [5/30], Step: [201/625], Validation Acc: 90.64\n",
      "Epoch: [5/30], Step: [301/625], Validation Acc: 90.78\n",
      "Epoch: [5/30], Step: [401/625], Validation Acc: 90.46\n",
      "Epoch: [5/30], Step: [501/625], Validation Acc: 90.68\n",
      "Epoch: [5/30], Step: [601/625], Validation Acc: 90.94\n",
      "Learning rate: 0.0025, Validation Acc: 89.76\n",
      "Epoch: [6/30], Step: [101/625], Validation Acc: 90.84\n",
      "Epoch: [6/30], Step: [201/625], Validation Acc: 90.72\n",
      "Epoch: [6/30], Step: [301/625], Validation Acc: 90.76\n",
      "Epoch: [6/30], Step: [401/625], Validation Acc: 90.7\n",
      "Epoch: [6/30], Step: [501/625], Validation Acc: 90.18\n",
      "Epoch: [6/30], Step: [601/625], Validation Acc: 90.62\n",
      "Learning rate: 0.0025, Validation Acc: 90.64\n",
      "Epoch: [7/30], Step: [101/625], Validation Acc: 90.54\n",
      "Epoch: [7/30], Step: [201/625], Validation Acc: 90.5\n",
      "Epoch: [7/30], Step: [301/625], Validation Acc: 90.58\n",
      "Epoch: [7/30], Step: [401/625], Validation Acc: 90.68\n",
      "Epoch: [7/30], Step: [501/625], Validation Acc: 90.66\n",
      "Epoch: [7/30], Step: [601/625], Validation Acc: 89.28\n",
      "Learning rate: 0.00125, Validation Acc: 89.66\n",
      "Epoch: [8/30], Step: [101/625], Validation Acc: 90.6\n",
      "Epoch: [8/30], Step: [201/625], Validation Acc: 90.56\n",
      "Epoch: [8/30], Step: [301/625], Validation Acc: 90.66\n",
      "Epoch: [8/30], Step: [401/625], Validation Acc: 90.58\n",
      "Epoch: [8/30], Step: [501/625], Validation Acc: 90.6\n",
      "Epoch: [8/30], Step: [601/625], Validation Acc: 90.72\n",
      "Learning rate: 0.00125, Validation Acc: 90.54\n",
      "Epoch: [9/30], Step: [101/625], Validation Acc: 90.58\n",
      "Epoch: [9/30], Step: [201/625], Validation Acc: 90.6\n",
      "Epoch: [9/30], Step: [301/625], Validation Acc: 90.54\n",
      "Epoch: [9/30], Step: [401/625], Validation Acc: 90.52\n",
      "Epoch: [9/30], Step: [501/625], Validation Acc: 90.72\n",
      "Epoch: [9/30], Step: [601/625], Validation Acc: 90.76\n",
      "Learning rate: 0.00125, Validation Acc: 90.64\n",
      "Epoch: [10/30], Step: [101/625], Validation Acc: 90.62\n",
      "Epoch: [10/30], Step: [201/625], Validation Acc: 90.68\n",
      "Epoch: [10/30], Step: [301/625], Validation Acc: 90.58\n",
      "Epoch: [10/30], Step: [401/625], Validation Acc: 90.52\n",
      "Epoch: [10/30], Step: [501/625], Validation Acc: 90.6\n",
      "Epoch: [10/30], Step: [601/625], Validation Acc: 90.66\n",
      "Learning rate: 0.000625, Validation Acc: 90.68\n",
      "Epoch: [11/30], Step: [101/625], Validation Acc: 90.58\n",
      "Epoch: [11/30], Step: [201/625], Validation Acc: 90.64\n",
      "Epoch: [11/30], Step: [301/625], Validation Acc: 90.64\n",
      "Epoch: [11/30], Step: [401/625], Validation Acc: 89.96\n",
      "Epoch: [11/30], Step: [501/625], Validation Acc: 90.56\n",
      "Epoch: [11/30], Step: [601/625], Validation Acc: 90.46\n",
      "Learning rate: 0.000625, Validation Acc: 90.66\n",
      "Epoch: [12/30], Step: [101/625], Validation Acc: 90.5\n",
      "Epoch: [12/30], Step: [201/625], Validation Acc: 90.68\n",
      "Epoch: [12/30], Step: [301/625], Validation Acc: 90.42\n",
      "Epoch: [12/30], Step: [401/625], Validation Acc: 90.76\n",
      "Epoch: [12/30], Step: [501/625], Validation Acc: 90.54\n",
      "Epoch: [12/30], Step: [601/625], Validation Acc: 90.66\n",
      "Learning rate: 0.000625, Validation Acc: 90.72\n",
      "Epoch: [13/30], Step: [101/625], Validation Acc: 90.66\n",
      "Epoch: [13/30], Step: [201/625], Validation Acc: 90.52\n",
      "Epoch: [13/30], Step: [301/625], Validation Acc: 90.64\n",
      "Epoch: [13/30], Step: [401/625], Validation Acc: 90.6\n",
      "Epoch: [13/30], Step: [501/625], Validation Acc: 90.56\n",
      "Epoch: [13/30], Step: [601/625], Validation Acc: 90.56\n",
      "Learning rate: 0.0003125, Validation Acc: 90.72\n",
      "Epoch: [14/30], Step: [101/625], Validation Acc: 90.68\n",
      "Epoch: [14/30], Step: [201/625], Validation Acc: 90.54\n",
      "Epoch: [14/30], Step: [301/625], Validation Acc: 90.7\n",
      "Epoch: [14/30], Step: [401/625], Validation Acc: 90.64\n",
      "Epoch: [14/30], Step: [501/625], Validation Acc: 90.5\n",
      "Epoch: [14/30], Step: [601/625], Validation Acc: 90.52\n",
      "Learning rate: 0.0003125, Validation Acc: 90.6\n",
      "Epoch: [15/30], Step: [101/625], Validation Acc: 90.6\n",
      "Epoch: [15/30], Step: [201/625], Validation Acc: 90.72\n",
      "Epoch: [15/30], Step: [301/625], Validation Acc: 90.54\n",
      "Epoch: [15/30], Step: [401/625], Validation Acc: 90.58\n",
      "Epoch: [15/30], Step: [501/625], Validation Acc: 90.46\n",
      "Epoch: [15/30], Step: [601/625], Validation Acc: 90.68\n",
      "Learning rate: 0.0003125, Validation Acc: 90.5\n",
      "Epoch: [16/30], Step: [101/625], Validation Acc: 90.46\n",
      "Epoch: [16/30], Step: [201/625], Validation Acc: 90.54\n",
      "Epoch: [16/30], Step: [301/625], Validation Acc: 90.56\n",
      "Epoch: [16/30], Step: [401/625], Validation Acc: 90.68\n",
      "Epoch: [16/30], Step: [501/625], Validation Acc: 90.5\n",
      "Epoch: [16/30], Step: [601/625], Validation Acc: 90.7\n",
      "Learning rate: 0.00015625, Validation Acc: 90.74\n",
      "Epoch: [17/30], Step: [101/625], Validation Acc: 90.6\n",
      "Epoch: [17/30], Step: [201/625], Validation Acc: 90.5\n",
      "Epoch: [17/30], Step: [301/625], Validation Acc: 90.54\n",
      "Epoch: [17/30], Step: [401/625], Validation Acc: 90.5\n",
      "Epoch: [17/30], Step: [501/625], Validation Acc: 90.42\n",
      "Epoch: [17/30], Step: [601/625], Validation Acc: 90.6\n",
      "Learning rate: 0.00015625, Validation Acc: 90.52\n",
      "Epoch: [18/30], Step: [101/625], Validation Acc: 90.74\n",
      "Epoch: [18/30], Step: [201/625], Validation Acc: 90.42\n",
      "Epoch: [18/30], Step: [301/625], Validation Acc: 90.52\n",
      "Epoch: [18/30], Step: [401/625], Validation Acc: 90.54\n",
      "Epoch: [18/30], Step: [501/625], Validation Acc: 90.5\n",
      "Epoch: [18/30], Step: [601/625], Validation Acc: 90.54\n",
      "Learning rate: 0.00015625, Validation Acc: 90.56\n",
      "Epoch: [19/30], Step: [101/625], Validation Acc: 90.64\n",
      "Epoch: [19/30], Step: [201/625], Validation Acc: 90.52\n",
      "Epoch: [19/30], Step: [301/625], Validation Acc: 90.56\n",
      "Epoch: [19/30], Step: [401/625], Validation Acc: 90.64\n",
      "Epoch: [19/30], Step: [501/625], Validation Acc: 90.54\n",
      "Epoch: [19/30], Step: [601/625], Validation Acc: 90.6\n",
      "Learning rate: 7.8125e-05, Validation Acc: 90.58\n",
      "Epoch: [20/30], Step: [101/625], Validation Acc: 90.54\n",
      "Epoch: [20/30], Step: [201/625], Validation Acc: 90.58\n",
      "Epoch: [20/30], Step: [301/625], Validation Acc: 90.52\n",
      "Epoch: [20/30], Step: [401/625], Validation Acc: 90.6\n",
      "Epoch: [20/30], Step: [501/625], Validation Acc: 90.56\n",
      "Epoch: [20/30], Step: [601/625], Validation Acc: 90.56\n",
      "Learning rate: 7.8125e-05, Validation Acc: 90.62\n",
      "Epoch: [21/30], Step: [101/625], Validation Acc: 90.5\n",
      "Epoch: [21/30], Step: [201/625], Validation Acc: 90.54\n",
      "Epoch: [21/30], Step: [301/625], Validation Acc: 90.74\n",
      "Epoch: [21/30], Step: [401/625], Validation Acc: 90.52\n",
      "Epoch: [21/30], Step: [501/625], Validation Acc: 90.52\n",
      "Epoch: [21/30], Step: [601/625], Validation Acc: 90.6\n",
      "Learning rate: 7.8125e-05, Validation Acc: 90.54\n",
      "Epoch: [22/30], Step: [101/625], Validation Acc: 90.58\n",
      "Epoch: [22/30], Step: [201/625], Validation Acc: 90.6\n",
      "Epoch: [22/30], Step: [301/625], Validation Acc: 90.5\n",
      "Epoch: [22/30], Step: [401/625], Validation Acc: 90.54\n",
      "Epoch: [22/30], Step: [501/625], Validation Acc: 90.56\n",
      "Epoch: [22/30], Step: [601/625], Validation Acc: 90.56\n",
      "Learning rate: 3.90625e-05, Validation Acc: 90.52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [23/30], Step: [101/625], Validation Acc: 90.58\n",
      "Epoch: [23/30], Step: [201/625], Validation Acc: 90.54\n",
      "Epoch: [23/30], Step: [301/625], Validation Acc: 90.54\n",
      "Epoch: [23/30], Step: [401/625], Validation Acc: 90.58\n",
      "Epoch: [23/30], Step: [501/625], Validation Acc: 90.48\n",
      "Epoch: [23/30], Step: [601/625], Validation Acc: 90.56\n",
      "Learning rate: 3.90625e-05, Validation Acc: 90.64\n",
      "Epoch: [24/30], Step: [101/625], Validation Acc: 90.52\n",
      "Epoch: [24/30], Step: [201/625], Validation Acc: 90.52\n",
      "Epoch: [24/30], Step: [301/625], Validation Acc: 90.58\n",
      "Epoch: [24/30], Step: [401/625], Validation Acc: 90.52\n",
      "Epoch: [24/30], Step: [501/625], Validation Acc: 90.52\n",
      "Epoch: [24/30], Step: [601/625], Validation Acc: 90.54\n",
      "Learning rate: 3.90625e-05, Validation Acc: 90.56\n",
      "Epoch: [25/30], Step: [101/625], Validation Acc: 90.56\n",
      "Epoch: [25/30], Step: [201/625], Validation Acc: 90.54\n",
      "Epoch: [25/30], Step: [301/625], Validation Acc: 90.54\n",
      "Epoch: [25/30], Step: [401/625], Validation Acc: 90.56\n",
      "Epoch: [25/30], Step: [501/625], Validation Acc: 90.54\n",
      "Epoch: [25/30], Step: [601/625], Validation Acc: 90.54\n",
      "Learning rate: 1.953125e-05, Validation Acc: 90.54\n",
      "Epoch: [26/30], Step: [101/625], Validation Acc: 90.54\n",
      "Epoch: [26/30], Step: [201/625], Validation Acc: 90.5\n",
      "Epoch: [26/30], Step: [301/625], Validation Acc: 90.54\n",
      "Epoch: [26/30], Step: [401/625], Validation Acc: 90.54\n",
      "Epoch: [26/30], Step: [501/625], Validation Acc: 90.58\n",
      "Epoch: [26/30], Step: [601/625], Validation Acc: 90.58\n",
      "Learning rate: 1.953125e-05, Validation Acc: 90.54\n",
      "Epoch: [27/30], Step: [101/625], Validation Acc: 90.54\n",
      "Epoch: [27/30], Step: [201/625], Validation Acc: 90.6\n",
      "Epoch: [27/30], Step: [301/625], Validation Acc: 90.54\n",
      "Epoch: [27/30], Step: [401/625], Validation Acc: 90.54\n",
      "Epoch: [27/30], Step: [501/625], Validation Acc: 90.54\n",
      "Epoch: [27/30], Step: [601/625], Validation Acc: 90.56\n",
      "Learning rate: 1.953125e-05, Validation Acc: 90.52\n",
      "Epoch: [28/30], Step: [101/625], Validation Acc: 90.54\n",
      "Epoch: [28/30], Step: [201/625], Validation Acc: 90.56\n",
      "Epoch: [28/30], Step: [301/625], Validation Acc: 90.54\n",
      "Epoch: [28/30], Step: [401/625], Validation Acc: 90.54\n",
      "Epoch: [28/30], Step: [501/625], Validation Acc: 90.56\n",
      "Epoch: [28/30], Step: [601/625], Validation Acc: 90.54\n",
      "Learning rate: 9.765625e-06, Validation Acc: 90.54\n",
      "Epoch: [29/30], Step: [101/625], Validation Acc: 90.52\n",
      "Epoch: [29/30], Step: [201/625], Validation Acc: 90.56\n",
      "Epoch: [29/30], Step: [301/625], Validation Acc: 90.56\n",
      "Epoch: [29/30], Step: [401/625], Validation Acc: 90.54\n",
      "Epoch: [29/30], Step: [501/625], Validation Acc: 90.58\n",
      "Epoch: [29/30], Step: [601/625], Validation Acc: 90.54\n",
      "Learning rate: 9.765625e-06, Validation Acc: 90.54\n",
      "Epoch: [30/30], Step: [101/625], Validation Acc: 90.54\n",
      "Epoch: [30/30], Step: [201/625], Validation Acc: 90.54\n",
      "Epoch: [30/30], Step: [301/625], Validation Acc: 90.54\n",
      "Epoch: [30/30], Step: [401/625], Validation Acc: 90.56\n",
      "Epoch: [30/30], Step: [501/625], Validation Acc: 90.54\n",
      "Epoch: [30/30], Step: [601/625], Validation Acc: 90.54\n",
      "Learning rate: 9.765625e-06, Validation Acc: 90.54\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 30\n",
    "learning_rate = 0.005\n",
    "train_accuracy_noreg = []\n",
    "val_accuracy_noreg = []\n",
    "val_accuracy_old = 0\n",
    "best_performing_model = model\n",
    "for epoch in range(num_epochs):\n",
    "    if epoch > 0 and epoch % 3 == 0:\n",
    "        learning_rate = learning_rate / 2\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    for i, (data, lengths, labels) in enumerate(train_loader):\n",
    "        model.train()\n",
    "        data_batch, length_batch, label_batch = data, lengths, labels\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data_batch, length_batch)\n",
    "        loss = criterion(outputs, label_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # validate every 300 iterations\n",
    "        if i > 0 and i % 100 == 0:\n",
    "            # validate\n",
    "            val_acc = test_model(val_loader, model)\n",
    "            print('Epoch: [{}/{}], Step: [{}/{}], Validation Acc: {}'.format( \n",
    "                        epoch+1, num_epochs, i+1, len(train_loader), val_acc))\n",
    "            if val_acc > val_accuracy_old:\n",
    "                best_performing_model = model\n",
    "                val_accuracy_old = val_acc\n",
    "    trainacc = test_model(train_loader, model)\n",
    "    valacc = test_model(val_loader, model)\n",
    "    train_accuracy.append(trainacc)\n",
    "    val_accuracy.append(valacc)\n",
    "    print('Learning rate: {}, Validation Acc: {}'.format( \n",
    "                       learning_rate, valacc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.54"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(val_loader, best_performing_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_accuracy1 = val_accuracy[0:30]\n",
    "train_accuracy1 = train_accuracy[0:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3Xd4VFX++PH3SSdtQkISIIEEBIQACYQYQAFFioIFUFQQ7GJf289V1LWsq7vq2le/utgLUhQpoiBREHCVLiUJJZQAoaRCCiFt5vz+uJPQUiYzE5IZPq/nyTMzd+aeOTdz5zPnnqq01gghhHBfHs2dASGEEE1LAr0QQrg5CfRCCOHmJNALIYSbk0AvhBBuTgK9EEK4OQn0Qgjh5iTQCyGEm5NAL4QQbs6ruTMA0KZNGx0bG9vc2RBCCJeyfv36PK11eEOvaxGBPjY2lnXr1jV3NoQQwqUopfba8jqpuhFCCDcngV4IIdycBHohhHBzEuiFEMLNSaAXQgg312CgV0p9opTKUUqlnrQtVCmVopTKsN62tm5XSql3lFI7lVKblVKJTZl5IYQQDbOlRP8ZcPlp26YCv2ituwK/WB8DjAK6Wv/uAt53TjaFEELYq8F+9FrrFUqp2NM2jwEusd7/HPgVeMK6/QttrE+4SikVopRqp7U+5KwMO11VBZTmw7Fc4680H1q1hq4jmjtn9qssg2M5UGL9O5YDVeWgLWAxG7d1/snSkk4Vfj70Ht/cuXCcxQwl2VB4AKqOg7nS2GapAkulcWuusj62bmuKc0lr63lay3lsOe2xqzj/cojq16RvYe+Aqcjq4K21PqSUirBujwL2n/S6LOu2MwK9UuoujFI/HTt2tDMbNjJXwfpPITvNGtDzoDTPuF9WWMsOCqbuA7/gps2XI7LTIGMJFGcbX8BjucZtSXYdx2Qr5bQsCg3KE+LGgmeLGJtYt4pSKMyCwv3Wvyw4uv/EtqIDRgB3KS5yLge1bbGBvi61/Wdr/VnXWk8DpgEkJSU1XTHy6D6YMwX2rwL/NhAYAf5h0DYeAtpAQLhx62+9f3AD/PSUcYL7xTVZtuyiNez6BX5/F3YvM7b5BBrHFBgJET2g8yUnHgdGGscUGAHe/qAUKA8j+CiPU/88PI3nhfOs+xQWPgzFhyCkQ3PnpnaFWfDj47D9h1O3K08Ibg+maOjQ37g1RYOpA/gEgIeX8efpdeL+GX+eTZPnU87Z085jZT2P5Vw+hb2BPru6SkYp1Q7IsW7PAk4+o6OBg45k0CGpc+D7RwAN13wE8dc1vI+yNlsUHYDIFhLoq8phyzfwx3uQk24E8EufgX63Gj9SomUyRRu3RQdaXqC3mGHtR/DLC8b9ix6GyJ4ngnlQu5Z/FSJsZu8nuQC4BXjZejv/pO0PKKVmAv2Bwmapny8vgUWPw8bpEH0BXPsRtI61bV9TlHFbmNVk2bNZaQGs+xjWfGhUyUT0hLHvQ69rwcu3uXMnGhLcgs6lk2WnwYIH4cA6OO9SuPJN278fwiU1GOiVUjMwGl7bKKWygOcwAvxspdQdwD6guqj8IzAa2AmUArc1QZ7rd2ADzLkTjuyBIY/DxU80rmQS2NYo1RcdaLo8NiR/l1F63/i10fB13jAY9wF0HiqXpK6kutDQnOfSySrLYMWr8L+3wc8E13wIva+Tc+ocYEuvm4l1PDWsltdq4H5HM2UXiwV+fweW/sOo2rhlIcRe1Ph0PL0gqH3zlMIsZph3H2yeBZ7e0Pt6GHh/y6lCEo3jZwKfIKOnSnPbswK+fxgKdkHCRBj5EgSENXeuxFniHpVwRYdg7t2wZzn0uBqufsfoImkvU1TzBPo1H8LmmTDgPqPONCjy7OdBOJcpqnlL9KUFkPIM/PmVUT1z0zw4b2jz5Uc0C9cP9Nt+hPn3Q1UZXPUOJN7s+KVocBQc2uic/Nnq6H6jYazLcLjsn3I57S6Cm6nQAJA2D358zAj2Fz1sVGP6+DdPXkSzcu1A//t/YMnfoG1vuPYTCO/mnHRN0bDtB6M749kIuFrDD48CGq54Q4K8OzFFweHNZ/99D22Gb26Bdn1g8nfQLv7s50G0GK4d6LteZgwUGvq0c3uhmKLBXG4MrApscJUux6XOMQY/XfYvaB3T9O8nzp7gaOMcrSo/uz2llv0T/ELg5vnQKuTsva9okVx79srwbjDiBed/gaq7xRWdhUvu0gJY9AS0T4T+dzf9+4mzqzl63mStgx2L4KIHJcgLwNUDfVOp6Ut/Fr6cS/4GZUeNBuSmGkkomk/1oKmz2fNm6YvGSO9kKTgIgwT62pisoxibuhFt1zJjUNeFDxrtDML9BFcH+rPUIJv5mzE9xuBHwTfw7LynaPEk0NfGPwy8/Jq26qai1JgHJbQzXPx4072PaF7B7Y3bs1ENqDUsfcmYviDp9qZ/P+EyXLsxtqkoZXxBm/Jye/nLcCQTbvkevFs13fuI5uXjD61Cz07Vza6lsO93uOJ1OafEKaREX5fgJhzocmiTMQNl35ug05CmeQ/RcpyNQVNaG3Xzpo7Q9+amfS/hciTQ18XUoWnqVc1VsOAvRvXQyH84P33R8gRHN32JfvsiY4rtS54AL5+mfS/hciTQ18UUZcwjbnbyYgur/s8o0Y9+1bFpGoTrMEU1bR29xQLLXoLQ8yB+QtO9j3BZEujrEhxlLEdWcth5aRbsMQaydBtlrDokzg3BUcaqX+UlTZN++lzIToWhT8kc8qJWEujr4uz+z1obvWw8vIzGMpnm4Nxx8gIkzmaugmX/gog46HmN89MXbkECfV1qAv3++l9nq00zYfevMPy5EwOyxLmhKRcg2TIb8jOM0ryHfJ1F7eTMqEuwE4eul+TCT09CdDIk3eF4esK1NNU0CFUV8OvL0C4Bul/p3LSFW5EKvbr4BYNvsHOqbjZ8BserpzmQ39ZzTlB7QDm/583Gr+DoXqkKFA2SqFMfU7RzLrdztxvdNSN6OJ6WcD1ePhAY4dyeN5VlsPzf0KG/sYaBEPWQEn19gp3ULS4vA8LOczwd4bqCo5xbol//KRQfhGv+K6V50SAp0dfH5IQvp9bGYt9tujonT8I1maKdV0dfcQxWvm6MqpaR1cIGEujrExwNpXlQedz+NEqyoaIYwro4L1/C9Ziso2O1djytNdOsC+78zfG0xDlBAn19avo/H7Q/jfydxq0E+nNbcBRUHjPWHnBEWSH89hZ0HQkd+zsnb8LtSaCvj8kJ/Z/zMoxbqbo5tzlrMZv1nxk/FkOfcjhL4twhgb4+zuhLn7/TmNu+egEKcW5y1gIkWeuMOW3a93U8T+KcIYG+PsFOKIXl7zS+mNJ//txmctI6xLnbpZuuaDSJPvXx9oOAcMemQcjfKV0rBQRGGvMcOVJoqKqAgl0Qfr7z8iXOCQ4FeqXUQ0qpVKVUmlLqYeu2PkqpVUqpjUqpdUqpZOdktZk4sgCJudJYRUrq54WHp7HEnyPVgAW7wVIF4d2dly9xTrA70CulegFTgGQgAbhSKdUVeBX4u9a6D/Cs9bHrMjmwaMSRvcYXU3rcCHB80FTuNuNWSvSikRwp0fcAVmmtS7XWVcByYByggWDra0yAA30TW4DgKPsb0PKtPW7CpEQvcHwBktztgJLzSTSaI4E+FRiilApTSvkDo4EOwMPAv5VS+4HXgCcdz2YzMkUbA57KChu/b3XXSqmjF2CtBjxorAhlj9xt0DrGWHBciEawO9BrrbcCrwApwGJgE1AF3As8orXuADwCfFzb/kqpu6x1+Otyc3PtzUbTc6T/c/5OY21Y/1Dn5km4JlM0mCuM0db2yN0m9fPCLg41xmqtP9ZaJ2qthwAFQAZwC/Cd9SXfYNTh17bvNK11ktY6KTw83JFsNK1gB1YHyt8pl9niBEcWIDFXGVeIUj8v7OBor5sI621H4BpgBkad/MXWl1yKEfxdlyMrTeXvlIZYcYIjC5Ac2QOWSinRC7s4Ok3xHKVUGFAJ3K+1PqKUmgK8rZTyAsqAuxzNZLMKagvKs/FVN2VFxoRmbSTQCytTB+PWnmpA6XEjHOBQoNdaD65l229AP0fSbVHs7f8sk5mJ0/mHGdNh2NPzpjrQt5FALxpPRsbawmRHF8uaQC919MJKKQhub2eJfjuYOoJvoPPzJdyeBHpb2LOkYP5OUB4Q2qlp8iRck70jrXO3SbWNsJsEeltU939uzKIReRkQ0hG8fJsuX8L12DPS2mKWHjfCIRLobWGKBnM5HGtE/2fpWilqExwFxYeM4G2ro3uhqkx63Ai7SaC3RU3/Zxu7WFavEysNseJ0pijQZig+bPs+uduNWwn0wk4S6G1hauSgqaKDxrJx0rVSnM6eBUhqulZ2c35+xDlBAr0tagZN2RjopWulqIs9C5Dkboeg9uBnapo8Cbcngd4Wje3/LLNWirrYs2qZ9LgRDpJAbwulGjddcf4u8PY3BloJcTI/E/gE2l4NaLFA7g6pnxcOkUBvK1MjFo3IyzCmJpZ1YsXpGltoKMoy2nukRC8cIJHIVsHRtpfCZDIzUR9TIwZNSY8b4QQS6G1lsvZ/NlfV/7qqcqPfs9TPi7o0ZklBmcxMOIEEeluZokFbjGBfnyOZxutkQXBRF1MHOJZjFAoakrsNAiJk8RrhEAn0trJ1ARJZPlA0pKaLpQ3LKedul9K8cJgEeluZbFwdSPrQi4YE27gAidbWQC/188IxEuhtZesycPkZxqW2DG4RdbF1AF7xISgvkhK9cJgEelv5BYOvyYaqm51SPy/qF2zj6NicrcatlOiFgyTQN4Ytfenzd0r9vKifjz+0at3wuSRdK4WTSKBvjOCo+kthx49AaZ50rRQNs2VcRu42aBUKAW3OTp6E25JA3xgNLSmYv8u4laob0RBbrg6rG2KVOjt5Em5LAn1jmKKhNB8qj9f+fE3XSulxIxrQ0NWh1jKZmXAaCfSNUdOXvo7+z/k7QXlC69izliXhokxRRlVfxbHany/JgbKjUj8vnEICfWOYGlhpKj/DCPKe3mctS8JFBTfQxbJ66oMICfTCcRLoG6Oh/s/5u6R+XtimoQVIpMeNcCIJ9I1R34hGi0XWiRW2a2gBktxtxqC7wMizlyfhtiTQN4aXLwSE197zpugAVB2XQC9sE9zeuK2ri6X0uBFOJIG+sepaNCJfetyIRvDyNUrrdXXXlR43wokcCvRKqYeUUqlKqTSl1MMnbf+LUmq7dfurjmezBTHVMdAlzzqZmdTRC1sF17EAybE8Y+Cd1M8LJ/Gyd0elVC9gCpAMVACLlVI/ANHAGCBea12ulIpwSk5bClM07F5+5vb8neATJHWqwnamKGM92NPVNMRKiV44hyMl+h7AKq11qda6ClgOjAPuBV7WWpcDaK1zHM9mCxIcBRXFUFZ46vZ86zqxUqcqbFU9DYLWp26vWVVKSvTCORwJ9KnAEKVUmFLKHxgNdAC6AYOVUquVUsuVUhfUtrNS6i6l1Dql1Lrc3FwHsnGW1TUvfb7MWikayRQFFSVnFhpyt4NP4ImeOUI4yO5Ar7XeCrwCpACLgU1AFUZ1UGtgAPBXYLZSZxZztdbTtNZJWuuk8PBwe7Nx9pk6GLcnd4urPA5H90tDrGicurrrVjfEytWhcBKHGmO11h9rrRO11kOAAiADyAK+04Y1gAVwn+n3aptLvGAPoCXQi8apawCerColnMzuxlgApVSE1jpHKdURuAYYiBHYLwV+VUp1A3yAPIdz2lIEtTXmszm56ka6Vgp71FZoOH4ESg5LQ6xwKocCPTBHKRUGVAL3a62PKKU+AT5RSqVi9Ma5RevTW5tcmIcnBLU7tRQm68QKe9QUGk46l6p74UiJXjiRQ4Feaz24lm0VwGRH0m3xTu9Ln7cTgtqDb2Dz5Um4nupCw8nnUk2PGynRC+eRkbH2OH0BElk+UNjr9HMpdxt4tQJTx+bLk3A7EujtUT2i0WIxHudnSNdKYZ/TR8fmboPwbuAhX03hPHI22cPUAcwVxjD1Y/lGA5rUzwt7VC8pWN2MJT1uRBNwtDH23HTyoClzpXFfFgQX9giOBnO5Mb+Nl69Rupf6eeFkEujtcfJAl+pRjVJHL+xR3Ze+KAssZuO+lOiFk0mgt0fNQJcsKMkGD28IiWnePAnXZDppAZKyo8Z9CfTCySTQ28M/DLz8jEB/JBNCO4Gn/CuFHWoWnD8AhfupbBVBVqGiLGdr8+ZLtCh+fn5ER0fj7W3fetQSneyh1IneEvm7pH5e2C+gDXj6GoWG3O1kJT9LUHAwsWFh1DJFlDgHaa3Jz88nKyuLTp062ZWG9LqxlykKjuyFgt3QRnrcCDspZSwrWHQAcrdRFhRLmAR5cRKlFGFhYZSVldmdhgR6ewVHw+EtRo8J6VopHGGKhrwdcHQfeHpLkBdncPSckEBvL1M0WKRrpXCC4Cij0ADgaV8drLNccskl/PTTT6dse+utt7jvvvvq3S8w0Jj+4+DBg4wfP77OtNetW1dvOm+99RalpaU1j0ePHs3Ro0dtybpNEhISmDhxotPScxUS6O1lOmlRCCnRC0ecfC55NG+gnzhxIjNnzjxl28yZM20Oju3bt+fbb7+1+/1PD/Q//vgjISEhdqd3sq1bt2KxWFixYgXHjh1zSpq1qaqqarK07SWB3l7VvSX8TEaDmhD2qh6X4eENHs3bP2L8+PEsXLiQ8vJyADIzMzl48CCDBg2ipKSEYcOGkZiYSO/evZk/f/4Z+2dmZtKrVy8Ajh8/zoQJE4iPj+eGG27g+PHjNa+79957SUpKomfPnjz33HMAvPPOOxw8eJChQ4cydOhQAGJjY8nLM2Y5f+ONN+jVqxe9evXirbfeqnm/Hj16MGXKFHr27MnIkSNPeZ+Tff3119x0002MHDmSBQsW1GzfuXMnw4cPJyEhgcTERHbt2gXAq6++Su/evUlISGDq1KnAqVcleXl5xMbGAvDZZ59x3XXXcdVVVzFy5Mh6/1dffPEF8fHxJCQkcNNNN1FcXEynTp2orDRqCIqKioiNja157AzS68Ze1aWwsC6yEpBwTPW4jNPOpb9/n0b6wSKnvlVc+2Ceu6pnnc+HhYWRnJzM4sWLGTNmDDNnzuSGG25AKYWfnx9z584lODiYvLw8BgwYwNVXX11n/fH777+Pv78/mzdvZvPmzSQmJtY899JLLxEaGorZbGbYsGFs3ryZBx98kDfeeINly5bRps2phaf169fz6aefsnr1arTW9O/fn4svvpjWrVuTkZHBjBkz+PDDD7n++uuZM2cOkyefOYHurFmzSElJYfv27bz77rs1VymTJk1i6tSpjBs3jrKyMiwWC4sWLWLevHmsXr0af39/CgoKGvzf/vHHH2zevJnQ0FCqqqpq/V+lp6fz0ksv8b///Y82bdpQUFBAUFAQl1xyCT/88ANjx45l5syZXHvttXZ3payNlOjtVV0Kk/p54ajqc6mFTH1wcvXNydU2Wmueeuop4uPjGT58OAcOHCA7O7vOdFasWFETcOPj44mPj695bvbs2SQmJtK3b1/S0tJIT0+vN0+//fYb48aNIyAggMDAQK655hpWrlwJQKdOnejTpw8A/fr1IzMz84z9165dS3h4ODExMQwbNowNGzZw5MgRiouLOXDgAOPGjQOM/ur+/v78/PPP3Hbbbfj7+wMQGhra4P9txIgRNa+r63+1dOlSxo8fX/NDVv36O++8k08//RSATz/9lNtuu63B92sMKdHbyy8YelwFPa5s7pwIV2eKBuUBEXGnbK6v5N2Uxo4dy6OPPsqGDRs4fvx4TUl8+vTp5Obmsn79ery9vYmNjW2wy19tpf09e/bw2muvsXbtWlq3bs2tt97aYDr1rV3k6+tbc9/T07PWqpsZM2awbdu2mqqWoqIi5syZw/XXX1/n+9WWdy8vLyzWWWtPz3NAQEDN/br+V3Wle9FFF5GZmcny5csxm8011V/OIiV6R9zwlRHshXBEqxC4aS70v7u5cwIYPWguueQSbr/99lMaYQsLC4mIiMDb25tly5axd+/eetMZMmQI06dPByA1NZXNmzcDRpANCAjAZDKRnZ3NokWLavYJCgqiuLi41rTmzZtHaWkpx44dY+7cuQwefMa6R7WyWCx88803bN68mczMTDIzM5k/fz4zZswgODiY6Oho5s2bB0B5eTmlpaWMHDmSTz75pKZhuLrqJjY2lvXr1wPU2+hc1/9q2LBhzJ49m/z8/FPSBbj55puZOHGi00vzIIFeiJah8yVGwG8hJk6cyKZNm5gwYULNtkmTJrFu3TqSkpKYPn063bvXPyfPvffeS0lJCfHx8bz66qskJycDRhfHvn370rNnT26//XYuuuiimn3uuusuRo0aVdMYWy0xMZFbb72V5ORk+vfvz5133knfvn1tOpYVK1YQFRVFVNSJ3k1DhgwhPT2dQ4cO8eWXX/LOO+8QHx/PhRdeyOHDh7n88su5+uqrSUpKok+fPrz22msAPPbYY7z//vtceOGFNY3Etanrf9WzZ0+efvppLr74YhISEnj00UdP2efIkSNN0v1TtYTlXJOSknRD/WuFOBds3bqVHj16NHc2RDP49ttvmT9/Pl9++WWtz9d2biil1mutkxpKW+rohRCimf3lL39h0aJF/Pjjj02SvgR6IYRoZv/5z3+aNH2poxdCCDcngV4IIdycBHohhHBzEuiFEMLNSaAXQgCQn59Pnz596NOnD23btiUqKqrmcUVFhU1p3HbbbWzfvr3R733FFVfYPABKNJ5DvW6UUg8BUwAFfKi1fuuk5x4D/g2Ea63rHlkghGgRwsLC2LhxIwDPP/88gYGBPPbYY6e8RmuN1hoPj9rLiNXztTRGfn4+W7Zswc/Pj3379tGxY8fGZ94GVVVVeHmdmx0N7S7RK6V6YQT5ZCABuFIp1dX6XAdgBLDPGZkUQjSfnTt30qtXL+655x4SExM5dOgQd911V800wy+88ELNawcNGsTGjRupqqoiJCSEqVOnkpCQwMCBA8nJyak1/W+//ZaxY8dyww03MGvWrJrthw8fZsyYMTVT+q5evRowfkyqt1VPFzB58uSaaQzgxEIoP//8M8OHD2fChAk1I2mvuuoq+vXrR8+ePfnoo49q9vnhhx9ITEwkISGBkSNHYjab6dKlS800BWazmc6dO9s0k2VL48jPWw9glda6FEAptRwYB7wKvAk8Dpw5YbUQwjaLpp5YecpZ2vaGUS83erf09HQ+/fRTPvjgAwBefvnlmul4hw4dyvjx44mLO3VStsLCQi6++GJefvllHn30UT755JOaed1PNmPGDP71r39hMpmYPHkyf/3rXwG4//77GTFiBA888ABVVVWUlpayadMmXnnlFX7//XdCQ0NtCrqrVq0iPT295krh888/JzQ0lNLSUpKSkrj22mspLy/n3nvvZeXKlcTExFBQUICnpycTJ07k66+/5oEHHuCnn37iggsusGkmy5bGkTr6VGCIUipMKeUPjAY6KKWuBg5orTc5JYdCiGZ33nnnccEFF9Q8njFjBomJiSQmJrJ169Zapxlu1aoVo0aNAuqePvjAgQPs27ePAQMGEBcXh9lsZtu2bQD8+uuv3H23MdGbl5cXwcHBLF26lBtuuKEm2NoSdAcOHHhKddCbb75Zc5WRlZXFrl27+OOPPxg6dCgxMTGnpHvHHXfw+eefA/DJJ580yYRjZ4PdJXqt9Val1CtAClACbAKqgKeBkQ3tr5S6C7gLaLI6OSFcmh0l76Zy8hS8GRkZvP3226xZs4aQkBAmT55c6zTDPj4+Nfc9PT1rXWJv1qxZ5Ofn06lTJ8C4Cpg5cybPP/88cOY0x7ZMH2w2m095r5Pz/vPPP7NixQpWrVpFq1atGDRoUL3TB8fGxtK6dWuWLVvGn3/+yciRDYa2FsmhXjda64+11ola6yFAAZAJdAI2KaUygWhgg1KqbS37TtNaJ2mtk8LDwx3JhhDiLCoqKiIoKIjg4GAOHTp0xmLijTFjxgx+/vnnmumD16xZw4wZMwAYOnRoTVWR2WymqKiI4cOHM3PmzJoqm9qmD547dy5ms7nW9yssLCQ0NJRWrVqRlpbG2rVrAWM++KVLl9ZMJ3xyldAdd9zBpEmTmDBhQp2N0C2dQ7lWSkVYbzsC1wBfaK0jtNaxWutYIAtI1FofdjinQogWITExkbi4OHr16sWUKVNOmWa4MXbt2sXhw4dJSjox+WLXrl3x9fVl/fr1vPvuu/z000/07t2bpKQktm3bRnx8PI8//jhDhgyhT58+NfX5d999NykpKSQnJ7Nx48ZTFiM52RVXXEFpaSkJCQm88MIL9O/fH4DIyEjef/99xowZQ0JCApMmTarZZ9y4cRQWFnLrrbfadZwtgUPTFCulVgJhQCXwqNb6l9OezwSSGupeKdMUC2GQaYpbnlWrVvHkk0+ybNmyZs1Hs01TrLWud4SDtVQvhBAu6aWXXmLatGk1a+i6KtescBJCiLPg6aefZu/evQwcOLC5s+IQCfRCCOHmJNAL0cK0hOU9Rcvi6DkhgV6IFsTPz4/8/HwJ9qKG1pr8/Hz8/PzsTuPcnOFHiBYqOjqarKwscnNzmzsrogXx8/MjOjra7v0l0AvRgnh7e9eMEhXCWaTqRggh3JwEeiGEcHMS6IUQws1JoBdCCDcngV4IIdycBHohhHBzEuiFEMLNSaAXQgg3J4FeCCHcnAR6IYRwcxLohRDCzUmgF0IINyeBXggh3JwEeiGEcHMS6IUQws1JoBdCCDcngV4IIdycBHohhHBzEuiFEMLNSaAXQgg3J4FeCCHcnEOBXin1kFIqVSmVppR62Lrt30qpbUqpzUqpuUqpEOdkVQghhD3sDvRKqV7AFCAZSACuVEp1BVKAXlrreGAH8KQzMiqEEMI+jpToewCrtNalWusqYDkwTmu9xPoYYBUQ7WgmhRBC2M+RQJ8KDFFKhSml/IHRQIfTXnM7sKi2nZVSdyml1iml1uXm5jqQDSGEEPWxO9BrrbcCr2BU1SwGNgHVJXmUUk9bH0+vY/9pWuskrXVSeHi4vdkQQgjRAIcaY7XWH2utE7XWQ4ACIANAKXULcCUwSWutHc+mEEIIe3k5srNSKkJrnaOU6ghx+WZzAAAab0lEQVRcAwxUSl0OPAFcrLUudUYmhRBC2M+hQA/MUUqFAZXA/VrrI0qpdwFfIEUpBUaD7T0Ovo8QQgg7ORTotdaDa9nWxZE0hRBCOJeMjBVCCDcngV4IIdycBHohhHBzEuiFEMLNSaAXQgg3J4FeCCHcnAR6IYRwcxLohRDCzUmgF0IINyeBXggh3JwEeiGEcHMS6IUQws1JoBdCCDcngV4IIdycBHohhHBzEuiFcCGpBwr5/PdMp6f52f/2ODVN0bI4usJUs7NYNB4eqrmzcdZ9uz6LL1ftZerl3Rl4XlhzZ0ecBVVmC4/M2khGTgkj4iJpH9LKKem+mbKDX7bl0Dk8kCHdwp2S5rlCa83R0kqyi8vILionu6iMnKIyisqqbE7jsp5t6RfTuglz6eKBftbaffx3+W4WPzwEH6+We3Gitaas0kIrH0+npJd2sJCn5m7BYtFM/HAVE5M7MHVUD0ytvJ2SvmiZvl2fRUZOCQA/b83m5oGxDqd5rLyKlTvzAHhhYTqLHhqMt6fj3yWtNRVmC75ezjnnG/veuSXl5JdUUHi8kqOllRQdrzTuHze2FR6v4mhpBUXHKymvsuDr5YGvlye+3h74eXvi62Xc+nkb2/28PfDx9ORIaQU5pwT1cirMljPy4OftgcK2AmjnNgES6OsTGezH7rxjLE47zNUJ7Zs7O7VKO1jI3+alsuNwMbPuHkivKJND6R0rr+IvM/4kpJU33913IV/+sZcPV+7ml605vDCmF5f3auuknIuWpLSiijdSdtAvpjVHjlWQku6cQL8yI5eKKgt3DOrEx7/t4atVe7ntok4Op/vU3C38uj2XRQ8NJsTfx+H0aqO1Jq+kgozsYnZkF7M9u6Tmfl0lak8PhamVNyGtvAlu5U2Ivw++Xh5UmC2UVZopLqsir6SC8kozZZVmyqosxv0qC2aLJsjXi4hgXyKD/bggNtS4H+RHZLAfkdbt4UG++Hmf/R+4+rh0oB/SNZyOof58tWpviwv0xWWVvJGyg89/z6S1vw+Bfl7c+fk65j9wEZHBfnan++z8NPbkHWP6nf2Jbu3Pk6N7cGV8ex6fs5l7vlrPqF5t+fuYnkQE2f8eouX5eOUecorLeX9yIkvSsvn4tz0UHq90+CpuSVo2If7ePDmqOzuyi3kzZQdj+kQRGmB/cE5Jz2bGmv0A/Pun7bw0rrdDeax2tLSC7zcfYsdhI5hn5JRQcKyi5nlTK2/OjwziqoT2dI0IJDLYD1Mrb0z+3sZtK28Cfb1Qyr6qXrNF4+mi1cQuHeg9PBQ39u/Iy4u2kZFdTNfIoObOElprFm4+xD8WppNbUs6NyR3562Xnc6iwjPHv/86dn69j9t0D7arG+W5DFnM2ZPHgsK5ceF6bmu29o00seOAipq3Yzdu/ZPC/nXk8fUUPrk/qYPdJXZ/yKjPvLt3J7rxjlFdaKK+yln5q7lusj82UV1morOXStjZKKTqG+tM7ykR8tIneUSZ6RZkI8G38aWq2aA4VHufAkeOEBfoQExbglCqJ5pBXUs4Hy3dxec+29IsJBeC/K3bz6/YcxvSJsjvdKrOFX7blMKxHBF6eHjxzZRyj3l7JGynbeXGsfcH5aGkFT83dQve2QVwQG8pXq/dywwUdiI8OsTufYHyet322lj/3HSXQ14tukYGMjIuka2QQ50cG0S0ykPAg3yY536u5apAHFw/0ANf1i+aNJTuYvnofz1/ds1nzsju3hGfnp/Hbzjx6RQUz7eYk+nQwTvAQfx/entCXKV+u49HZG3nvxsRGNSLvyi3hb/NSSe4UyoOXdjnjeW9PD+4f2oVRvdoy9bstPDFnC/M3HuRf1/QmJizAacdYUl7FPV+u57edeXRuE2DUZ3p74OflSZtAr9PqN43nvD08sOX7Z7ZoduWWsC6zgAWbDgKgFHQJD6R3tIn4KBO9o0OIaxdMKx9PjleY2VdQyr6CUvbmH6u5vy+/lKwjx0+pO/Xx9KBzeIA1MATSNTKIbpFBdAz1r/ULXF0tYKR5jL35J9Lef6SUiirbfry6RgTx0a1JBPvZX/J+55cMyqosPH75+QD06dCaNoE+LEnPdijQr8ksoPB4JSPjjOq+bpFB3DQghi/+yOTG5Bji2gc3Os3nF6Rx5FgFn912AR1C/Vmcdphn5qUy976LHOo08dHK3fy57yj/Hh/P+H7RTRrQ3ZHLB/qwQF9G927LnPVZPH75+fj7nP1DKqs0896ynfx3+W58vT14YUxPJvWPOSOADI+L5OnRPXjxh628nrKdv17W3eb0H/j6T3y9PHhnQl+86imZdg4PZOaUAcxYu4+Xf9zGZW+t4JHh3bhjUKd697NFfkk5t322lrSDRbx2XQLj+0U7lF59covLST1QyKaso2zJKmTFjjy+23AAMEpWrf29ySupOGWfIF8vOob5071dECN6RhITGkBU61bkFZezI6eYjOwSNuw9wvfWHxEAXy8PukQE0i0yiNAAH/Zbfyz2F5RyrMJc8zqloG2wHx1D/RncNRx/G67Iqiya2Wv389jsTfz3pn52BafduSV8vXofE5M70Dk8sOb4h/eIZOHmQ5RXme1u8ExJz8bXy4Mh3U5cHT48vCvzNx7ghYVpzJgyoFF5Xpx6mHkbD/Lw8K70bG+0RT09ugcPz9rIrHX7mZjc0a58ZmQX83rKDi7rGSlB3k4uH+gBJg+IYd7GgyzYeJAJdp5M9lq6LZvnFqSxv+A44/pG8eTo7vXWj98xqBO7ckt4b9kuOrcJ5FobguU/f9zK1kNFfHJrEm1NDde9e3goJvWPYVj3SP42L5V/LdrGj6mHef26BLpEBDbq+KplHSnl5o/XcODocabd1I9hPSLtSsdW4UG+DO0ewdDuEYBRws4uKmdz1lG2HCgkp6icDqGt6BDqT0xYADGh/oT4e9sUBErKq9iZU1JT17sjp4Q/duVzpLTCSC/UnwGdw4gJ8ycmzJ+OoQFEt25lVwPbeeGB/GNhOh8s3829l5zX6P3//dN2fLw8eGhYt1O2j+wZycy1+/ljVz6XnB/R6HS11ixJy2Zw1zanFI5C/H14dOT5PDMvlcWphxnVu51N6RUcq+Bv87YQ1y6Y+4eeuOIc06c9X6/ZxyuLt3FZz7aNrvuvMlt47JtNBPh48uLY3hLk7aW1bva/fv36aUdYLBZ92ZvL9RXvrNAWi8WhtGx15Fi5vufLdTrmiYV62Ou/6t935tm8b0WVWU+c9ofu8tQPevXu/Hpfu2jLQR3zxEL9wvdpduXTYrHoBRsP6IS//6S7Pf2j/nDFLl1lbtz/aPvhIp38Uoru/dxivWZP/fkVp7JYLPr+6et1p6kL9f8ychu177rMAh3zxEL9VsqOM547XlGlezyzSD/13Wa78pV64KiOeWKhnrlm7xnPVVaZ9WVvLtcXvfyLPl5RZVN6909fr7s89YNOP1h4xnPbDhXpzk/+oKfO2dTofL67NEPHPLFQL9h4oNH7nguAddqGGOuarVOnUUoxaUAMqQeK2JRV2OTvt35vAaPfXskvW3P462Xn8+ODgxs1aMnb04P3J/WjQ2t/7v5yHfvyS2t93f6CUh7/djPx0SaeuNy2ap7TKaW4KqE9Sx4ZwuCu4bz4w1YmTPuDvfnHbNp//d4CrvvgD7SG2fcM5ILYULvyca5SSvHKtfF0Dg/kLzP+5HBhmU37aa15edFWwoN8uXPwmd0d/bw9ubhbOCnp2VgsutH5SknPRilqvTLz8vTg2SvjyDpynI9W7m4wrR+3HGLh5kM8eGlXerQ7s17//LZB3HZhLDPX7ufPfUdszuP2w8W8/XMGo3u35cp4264sRO0cCvRKqYeUUqlKqTSl1MPWbaFKqRSlVIb1tmlHAliN6xtFgI8nX63a22TvYbFo3v91F9f/dxVenh7MufdC7h/axa7BWiZ/bz6+9QIsGm7/fC1FZZWnPF9ptvDgzD+xaPjPxL4ODwiLCPLjw5v78dp1CWw7XMzlb63ky1V7MQoFtVu2PYdJH60mNMCHOfdeSPe2jW+cExDg68UHk/tRVmnmvunrbWrITUnPZm3mER4Z3q3OXkcj4iLJKS5n84HGF26WpGXTr2Nr2gT61vr8hV3acHnPtry3bBeHCo/XmU5eSTl/m5dK7ygT99RTNfXwiG5EBPny7Pw0zDb8MFVaq2yC/Lz4x5heUmXjILujh1KqFzAFSAYSgCuVUl2BqcAvWuuuwC/Wx00u0NeLsX2j+H7TQY6WVjS8QyNVN0S+sngbl/dqy8IHB9E72rHBT53aBPDB5H5k5h3j/ukbqDqpl8jrS3bw576jTu01o5RifL9ofnp4CEmxrXlmXio3WevdTzf3zyymfL6OLhGBfHPPQDqE+jslD+eqLhGB/Pu6BDbsO8o/f9xa72urzBZeXryN88IDuD6p7jacS7tH4OmhWJJ2uFF5yTpSSvqhIkb2rL+d5ekremDWmlcWbav1ea01z8xLpaSsiteuS6i3+2qgrxdPXxHHlgOFzFizr8E8fvDrLrYcKOTFsb0Iq+PHSNjOkWJiD2CV1rpUa10FLAfGAWOAz62v+RwY61gWbTepfwzlVRa+XZ/l1HRX785n9Dsr+WN3Pi+O7cW7E/s61F3uZAPPC+PFsb1YmZHHCwvTAVixI5cPlu9iYnIHrmqCgWDtQ1rxxe3JvDSuFxv2HeHyN1cwe93+mtL9x7/t4ZFZm0juFMqMKQPqLPWJxhndux13DurEZ79nMn/jgTpfN2vdfnbnHmPqqB719pQK8fchOTaUlPTsRuWj+vUj4uofRd0h1J+7Bndm3saDrN9bcMbzCzcfYlHqYR4e0ZXz2zY8huWq+HYM7BzGv3/aTn5JeZ2vSz9YxDtLM7gqob3NjcGifo4E+lRgiFIqTCnlD4wGOgCRWutDANbbxncJsFNc+2ASO4bw9ep99VZJ2Mps0fznlwwmfrgKfx8v5t53IZMHxDj9MnJCckfuGtKZL/7YyxspO3h09ka6RQby7JVNNy5AKaNnzuKHhtCjfTCPf7uZOz9fx4sL0/nHwnRG927Lp7ddQJCTftCE4YlR3bkgtjVT52xh++HiM54/Vl7FmykZJMeGMrxHw1+dkT0jycgpYU+ebW0uYAT6rhGBdGrT8JXivZecR2SwL3//Pv2UtoDc4nKenZ9KQocQ7hrc2ab3VUrxwpieHCuv4pXFtV8lVFfZmFp58/dmHhfjTuwO9FrrrcArQAqwGNgE2Dxlm1LqLqXUOqXUutzcXHuzcYbJA2LYnXeM33flO5RObnE5t3yyhtdTdnBVQnu+/8ugmr7BTeGJy7szvEck7/ySQUl5Fe/emOi0SdDq0zHMn5lTBvDMlXH8tjOPj37bw439O/KfiYnNMiGVu/P29OC9GxMJ9PPi3q/WU3xa28yHK3eTV1LOk6O721SgGBFnVL+kpNtWfXO0tILVewpq9mtIgK8XU0d1Z3NWIXM2GFfKWmv+Nm8LxyrMvH5dfKPGZ3SNDOKOwZ2YvS6L9XvPbJh9b9lO0g8V8eLY3g5NwyBO5VALn9b6Y611otZ6CFAAZADZSql2ANbbnDr2naa1TtJaJ4WHO29q1NG929Ha39uhRtn/7cxj1NsrWZtZwCvX9uatG/oQaMcw/Mbw9FC8PaEPV8S34/Xr+tDtLE7n4OGhuGNQJxY9NJh3b+zLS2N7ufRw75YuItiP925MZG9BKX/9ZnPN1WdOcRnTVuzmit7t6NvRtj4M0a39iWsXzJI026pvlm3PwWzRjOxp++R3Y/tEkdgxhFcWb6e4rJIFmw7yU1o2/29EN7pENP48ffDSrrQN9uOZeamnNMymHijk3aU7GdunvUzO52SO9rqJsN52BK4BZgALgFusL7kFmO/IezSWn7cn1yV1YEl6NtlFtnVlO9nnv2cy+ePVhPh7s+CBQdxwQcez1uIf4OvFezcmckUzdSXrHB7IlfHtpYfDWZDcKZQnR3Vncdphpq0wujC+/XMGFVUW/nrZ+Y1Ka2TPSNbvO0JePfXe1ZakZRMR5Et8I2ZRVUrx3FU9ySsp54Xv03l2fhp9O4Zwp41VNqcL8PXimSvjSD9UVFMgq6gyqmxaB/g0+1Qm7sjRfvRzlFLpwPfA/VrrI8DLwAilVAYwwvr4rLoxuSNmi2amdQY9W33xRybPLUhjeI9IFjxwkU0NTELY645BnRjduy2vLN7G9NV7mbl2P5MHxBBrQ935yUbERaI1/LK1/lJ9WaWZ5TtyGREX2eh5ZxI6hDC+XzTfrM+irNLMa9clOHTVN7p3WwZ1acNrS7aTW1zOf5ZmsO1wMf8a17vJpjU+lzladTNYax2ntU7QWv9i3ZavtR6mte5qvT2zub6JxbYJYHDXNsxYs++ULov1mb56L8/ON4L8ezcmNsucOeLcopTi1fEJxLYJ4Om5qbTy9uQvtUxY15C4dsFEhbRqsPrm9115lFaYba6fP93jl51PTJg/z1wZx3nh9k2lUU0pxd/H9LTO47SB//t1F9ckRjHczryJ+rnFyNjaTB4Qw+GiMn7ZVmsTwSlmrd3H03NTubR7BO9NcnxwkhC2CvT14r+T+9Ha35tHRnSzq8+4UooRcZGs3JnHsfK6+0MsScsm0NfL7qUnI4L9+PWxS5g8IMau/U93XnggUwZ3ZvWeAtoE+vBcE/YyO9e5bUQb1j2Cdia/Bhtlv1m3n6nfbeHibuH83yTpaSLOvq6RQax9ejh3DLJ/ZaeRPSOpqLKwMqP2Hmxmi+bnrdlcfH64Q+e4s9tvHri0C2P6tOedCX0x+UtX3qbitoHey9ODCRd0ZGVGHpl19DGe+2cWj8/ZzKAubfjvTf1a3PJf4tzh6BTSybGhmFp5s6SOwVMb9x8hr6SCkS2sasTfx4u3J/Slf2dZ4L4puW2gB5iQ3AFPD8XXtQy5XrDpIP9v9iYGdApj2k1JEuSFS/Py9GBY9wiWbsuptV1qSXo23p6qZtpncW5x60AfGezHyLhIvlm3n7LKE4tI/LD5EI/M2khSbCgf35p0VgYmCdHURvaM5GhpJWszzxyIlJKWzYDOYU6bukO4FrcO9GA0yh4preTHLYcAWJx6iAdn/knfDiF8eusF0rtGuI3BXcPx8fJgyWmjZHfmlLA771iLq7YRZ4/bB/oLzwujc5sAvlq1lyVph3ng6z9JiDbx2e3Jdi06LURLFeDrxeAubUhJzz5lrqfqwC9dF89dbh/olVLc2L8jG/Yd5b7pG+gZZQT5pp7SQIjmMCIukqwjx9l66MSEaUvSsomPNtHO1KoZcyaak9sHeoDx/aIJ8PGkR7tgvrg9Weophdsa1iMSpU5MRZxTVMbG/UcZ0cRr/IqW7Zwo1ob4+5Dy6MWEBvhI7xrh1sKDfEns2Jol6Yd5aHhXUqzTIjRmEjPhfs6JEj0Yi21IkBfngpFxkaQdLOLA0eOkpGfTMdSfbpGOTVkgXNs5E+iFOFdUl97n/XmA33fmMzIuUmYkPcdJoBfCzXRqE0CXiEDeW7aTCrPF7knMhPuQQC+EGxoZF0lphZnQAB/6xdi2iIlwXxLohXBD1aX4S7tHODyPjnB950SvGyHONQnRITww1JgZUggJ9EK4IQ8PxWONXJJQuC+5phNCCDcngV4IIdycBHohhHBzEuiFEMLNSaAXQgg3J4FeCCHcnAR6IYRwcxLohRDCzamTlxxrtkwolQvstXP3NkCeE7PTErjbMbnb8YD7HZO7HQ+43zHVdjwxWuvwhnZsEYHeEUqpdVrrpObOhzO52zG52/GA+x2Tux0PuN8xOXI8UnUjhBBuTgK9EEK4OXcI9NOaOwNNwN2Oyd2OB9zvmNzteMD9jsnu43H5OnohhBD1c4cSvRBCiHq4dKBXSl2ulNqulNqplJra3PlxlFIqUym1RSm1USm1rrnzYw+l1CdKqRylVOpJ20KVUilKqQzrrcusbVfH8TyvlDpg/Zw2KqVGN2ceG0sp1UEptUwptVUplaaUesi63SU/p3qOx2U/J6WUn1JqjVJqk/WY/m7d3kkptdr6Gc1SSvnYlJ6rVt0opTyBHcAIIAtYC0zUWqc3a8YcoJTKBJK01i7b91cpNQQoAb7QWveybnsVKNBav2z9QW6ttX6iOfNpqzqO53mgRGv9WnPmzV5KqXZAO631BqVUELAeGAvcigt+TvUcz/W46OeklFJAgNa6RCnlDfwGPAQ8CnyntZ6plPoA2KS1fr+h9Fy5RJ8M7NRa79ZaVwAzgTHNnKdzntZ6BVBw2uYxwOfW+59jfAldQh3H49K01oe01hus94uBrUAULvo51XM8LksbSqwPva1/GrgU+Na63ebPyJUDfRSw/6THWbj4h4vxQS5RSq1XSt3V3Jlxokit9SEwvpRARDPnxxkeUEpttlbtuEQVR22UUrFAX2A1bvA5nXY84MKfk1LKUym1EcgBUoBdwFGtdZX1JTbHPFcO9KqWba5ZD3XCRVrrRGAUcL+12kC0PO8D5wF9gEPA682bHfsopQKBOcDDWuui5s6Po2o5Hpf+nLTWZq11HyAaowajR20vsyUtVw70WUCHkx5HAwebKS9OobU+aL3NAeZifLjuINtaj1pdn5rTzPlxiNY62/oltAAf4oKfk7Xedw4wXWv9nXWzy35OtR2PO3xOAFrro8CvwAAgRCnlZX3K5pjnyoF+LdDV2grtA0wAFjRznuymlAqwNiShlAoARgKp9e/lMhYAt1jv3wLMb8a8OKw6GFqNw8U+J2tD38fAVq31Gyc95ZKfU13H48qfk1IqXCkVYr3fChiO0fawDBhvfZnNn5HL9roBsHaXegvwBD7RWr/UzFmym1KqM0YpHsAL+NoVj0cpNQO4BGOmvWzgOWAeMBvoCOwDrtNau0QDZx3HcwlGdYAGMoG7q+u2XYFSahCwEtgCWKybn8Ko13a5z6me45mIi35OSql4jMZWT4wC+Wyt9QvWODETCAX+BCZrrcsbTM+VA70QQoiGuXLVjRBCCBtIoBdCCDcngV4IIdycBHohhHBzEuiFEMLNSaAXQgg3J4FeCCHcnAR6IYRwc/8fkda+kBZifvgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(30), val_accuracy1, label=\"Validation Accuracy\")\n",
    "plt.plot(range(30), train_accuracy1, label=\"Train Accuracy\")\n",
    "plt.legend(loc = 'best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "max_vocab_size = 50000\n",
    "MAX_SENTENCE_LENGTH = 800\n",
    "emb_dim = 200\n",
    "BATCH_SIZE = 32\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "model = BagOfWords(len(id2token), emb_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/15], Step: [101/625], Validation Acc: 80.3\n",
      "Epoch: [1/15], Step: [201/625], Validation Acc: 84.2\n",
      "Epoch: [1/15], Step: [301/625], Validation Acc: 85.54\n",
      "Epoch: [1/15], Step: [401/625], Validation Acc: 84.94\n",
      "Epoch: [1/15], Step: [501/625], Validation Acc: 88.56\n",
      "Epoch: [1/15], Step: [601/625], Validation Acc: 89.56\n",
      "Learning rate: 0.005, Validation Acc: 88.4\n",
      "Epoch: [2/15], Step: [101/625], Validation Acc: 90.54\n",
      "Epoch: [2/15], Step: [201/625], Validation Acc: 89.94\n",
      "Epoch: [2/15], Step: [301/625], Validation Acc: 90.58\n",
      "Epoch: [2/15], Step: [401/625], Validation Acc: 90.14\n",
      "Epoch: [2/15], Step: [501/625], Validation Acc: 90.6\n",
      "Epoch: [2/15], Step: [601/625], Validation Acc: 90.58\n",
      "Learning rate: 0.005, Validation Acc: 90.44\n",
      "Epoch: [3/15], Step: [101/625], Validation Acc: 91.28\n",
      "Epoch: [3/15], Step: [201/625], Validation Acc: 90.82\n",
      "Epoch: [3/15], Step: [301/625], Validation Acc: 89.28\n",
      "Epoch: [3/15], Step: [401/625], Validation Acc: 90.58\n",
      "Epoch: [3/15], Step: [501/625], Validation Acc: 90.4\n",
      "Epoch: [3/15], Step: [601/625], Validation Acc: 90.8\n",
      "Learning rate: 0.005, Validation Acc: 90.54\n",
      "Epoch: [4/15], Step: [101/625], Validation Acc: 90.56\n",
      "Epoch: [4/15], Step: [201/625], Validation Acc: 90.54\n",
      "Epoch: [4/15], Step: [301/625], Validation Acc: 90.54\n",
      "Epoch: [4/15], Step: [401/625], Validation Acc: 90.26\n",
      "Epoch: [4/15], Step: [501/625], Validation Acc: 90.42\n",
      "Epoch: [4/15], Step: [601/625], Validation Acc: 90.6\n",
      "Learning rate: 0.0025, Validation Acc: 90.64\n",
      "Epoch: [5/15], Step: [101/625], Validation Acc: 89.62\n",
      "Epoch: [5/15], Step: [201/625], Validation Acc: 90.6\n",
      "Epoch: [5/15], Step: [301/625], Validation Acc: 90.56\n",
      "Epoch: [5/15], Step: [401/625], Validation Acc: 90.44\n",
      "Epoch: [5/15], Step: [501/625], Validation Acc: 90.1\n",
      "Epoch: [5/15], Step: [601/625], Validation Acc: 90.5\n",
      "Learning rate: 0.0025, Validation Acc: 90.56\n",
      "Epoch: [6/15], Step: [101/625], Validation Acc: 90.58\n",
      "Epoch: [6/15], Step: [201/625], Validation Acc: 90.4\n",
      "Epoch: [6/15], Step: [301/625], Validation Acc: 90.42\n",
      "Epoch: [6/15], Step: [401/625], Validation Acc: 90.44\n",
      "Epoch: [6/15], Step: [501/625], Validation Acc: 90.26\n",
      "Epoch: [6/15], Step: [601/625], Validation Acc: 90.18\n",
      "Learning rate: 0.0025, Validation Acc: 90.14\n",
      "Epoch: [7/15], Step: [101/625], Validation Acc: 90.18\n",
      "Epoch: [7/15], Step: [201/625], Validation Acc: 90.28\n",
      "Epoch: [7/15], Step: [301/625], Validation Acc: 90.28\n",
      "Epoch: [7/15], Step: [401/625], Validation Acc: 90.16\n",
      "Epoch: [7/15], Step: [501/625], Validation Acc: 90.2\n",
      "Epoch: [7/15], Step: [601/625], Validation Acc: 90.14\n",
      "Learning rate: 0.00125, Validation Acc: 90.32\n",
      "Epoch: [8/15], Step: [101/625], Validation Acc: 90.36\n",
      "Epoch: [8/15], Step: [201/625], Validation Acc: 90.24\n",
      "Epoch: [8/15], Step: [301/625], Validation Acc: 90.28\n",
      "Epoch: [8/15], Step: [401/625], Validation Acc: 90.24\n",
      "Epoch: [8/15], Step: [501/625], Validation Acc: 90.32\n",
      "Epoch: [8/15], Step: [601/625], Validation Acc: 90.28\n",
      "Learning rate: 0.00125, Validation Acc: 90.2\n",
      "Epoch: [9/15], Step: [101/625], Validation Acc: 90.28\n",
      "Epoch: [9/15], Step: [201/625], Validation Acc: 90.3\n",
      "Epoch: [9/15], Step: [301/625], Validation Acc: 90.28\n",
      "Epoch: [9/15], Step: [401/625], Validation Acc: 90.02\n",
      "Epoch: [9/15], Step: [501/625], Validation Acc: 90.1\n",
      "Epoch: [9/15], Step: [601/625], Validation Acc: 90.18\n",
      "Learning rate: 0.00125, Validation Acc: 90.26\n",
      "Epoch: [10/15], Step: [101/625], Validation Acc: 90.2\n",
      "Epoch: [10/15], Step: [201/625], Validation Acc: 90.3\n",
      "Epoch: [10/15], Step: [301/625], Validation Acc: 90.28\n",
      "Epoch: [10/15], Step: [401/625], Validation Acc: 90.1\n",
      "Epoch: [10/15], Step: [501/625], Validation Acc: 90.2\n",
      "Epoch: [10/15], Step: [601/625], Validation Acc: 90.2\n",
      "Learning rate: 0.000625, Validation Acc: 90.18\n",
      "Epoch: [11/15], Step: [101/625], Validation Acc: 90.22\n",
      "Epoch: [11/15], Step: [201/625], Validation Acc: 90.16\n",
      "Epoch: [11/15], Step: [301/625], Validation Acc: 90.2\n",
      "Epoch: [11/15], Step: [401/625], Validation Acc: 90.18\n",
      "Epoch: [11/15], Step: [501/625], Validation Acc: 90.14\n",
      "Epoch: [11/15], Step: [601/625], Validation Acc: 90.18\n",
      "Learning rate: 0.000625, Validation Acc: 90.22\n",
      "Epoch: [12/15], Step: [101/625], Validation Acc: 90.16\n",
      "Epoch: [12/15], Step: [201/625], Validation Acc: 90.24\n",
      "Epoch: [12/15], Step: [301/625], Validation Acc: 90.26\n",
      "Epoch: [12/15], Step: [401/625], Validation Acc: 90.2\n",
      "Epoch: [12/15], Step: [501/625], Validation Acc: 90.08\n",
      "Epoch: [12/15], Step: [601/625], Validation Acc: 90.12\n",
      "Learning rate: 0.000625, Validation Acc: 90.1\n",
      "Epoch: [13/15], Step: [101/625], Validation Acc: 90.1\n",
      "Epoch: [13/15], Step: [201/625], Validation Acc: 90.2\n",
      "Epoch: [13/15], Step: [301/625], Validation Acc: 90.1\n",
      "Epoch: [13/15], Step: [401/625], Validation Acc: 90.18\n",
      "Epoch: [13/15], Step: [501/625], Validation Acc: 90.16\n",
      "Epoch: [13/15], Step: [601/625], Validation Acc: 90.08\n",
      "Learning rate: 0.0003125, Validation Acc: 90.22\n",
      "Epoch: [14/15], Step: [101/625], Validation Acc: 90.24\n",
      "Epoch: [14/15], Step: [201/625], Validation Acc: 90.2\n",
      "Epoch: [14/15], Step: [301/625], Validation Acc: 90.08\n",
      "Epoch: [14/15], Step: [401/625], Validation Acc: 90.04\n",
      "Epoch: [14/15], Step: [501/625], Validation Acc: 90.2\n",
      "Epoch: [14/15], Step: [601/625], Validation Acc: 90.28\n",
      "Learning rate: 0.0003125, Validation Acc: 90.26\n",
      "Epoch: [15/15], Step: [101/625], Validation Acc: 90.3\n",
      "Epoch: [15/15], Step: [201/625], Validation Acc: 90.36\n",
      "Epoch: [15/15], Step: [301/625], Validation Acc: 90.22\n",
      "Epoch: [15/15], Step: [401/625], Validation Acc: 90.2\n",
      "Epoch: [15/15], Step: [501/625], Validation Acc: 90.18\n",
      "Epoch: [15/15], Step: [601/625], Validation Acc: 90.1\n",
      "Learning rate: 0.0003125, Validation Acc: 90.28\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 15\n",
    "learning_rate = 0.005\n",
    "train_accuracy_noreg2 = []\n",
    "val_accuracy_noreg2 = []\n",
    "val_accuracy_step2 = []\n",
    "highest_val_acc = 0\n",
    "best_performing_model2 = model\n",
    "for epoch in range(num_epochs):\n",
    "    if epoch > 0 and epoch % 3 == 0:\n",
    "        learning_rate = learning_rate / 2\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    for i, (data, lengths, labels) in enumerate(train_loader):\n",
    "        model.train()\n",
    "        data_batch, length_batch, label_batch = data, lengths, labels\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data_batch, length_batch)\n",
    "        loss = criterion(outputs, label_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # validate every 100 iterations\n",
    "        if i > 0 and i % 100 == 0:\n",
    "            # validate\n",
    "            val_acc = test_model(val_loader, model)\n",
    "            val_accuracy_step2.append(val_acc)\n",
    "            print('Epoch: [{}/{}], Step: [{}/{}], Validation Acc: {}'.format( \n",
    "                        epoch+1, num_epochs, i+1, len(train_loader), val_acc))\n",
    "            highest_val_acc = max(val_accuracy_step2)\n",
    "            if val_acc > highest_val_acc:\n",
    "                best_performing_model2 = model\n",
    "                \n",
    "    trainacc = test_model(train_loader, model)\n",
    "    valacc = test_model(val_loader, model)\n",
    "    train_accuracy_noreg2.append(trainacc)\n",
    "    val_accuracy_noreg2.append(valacc)\n",
    "    print('Learning rate: {}, Validation Acc: {}'.format( \n",
    "                       learning_rate, valacc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91.28"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highest_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.28"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(val_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.28"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(val_loader, best_performing_model2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_accuracy_noreg2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/10], Step: [301/625], Validation Acc: 70.82\n",
      "Epoch: [1/10], Step: [601/625], Validation Acc: 73.84\n",
      "Learning rate: 0.001, Validation Acc: 79.04\n",
      "Epoch: [2/10], Step: [301/625], Validation Acc: 83.58\n",
      "Epoch: [2/10], Step: [601/625], Validation Acc: 86.98\n",
      "Learning rate: 0.001, Validation Acc: 87.28\n",
      "Epoch: [3/10], Step: [301/625], Validation Acc: 88.18\n",
      "Epoch: [3/10], Step: [601/625], Validation Acc: 88.62\n",
      "Learning rate: 0.001, Validation Acc: 88.26\n",
      "Epoch: [4/10], Step: [301/625], Validation Acc: 89.38\n",
      "Epoch: [4/10], Step: [601/625], Validation Acc: 89.16\n",
      "Learning rate: 0.001, Validation Acc: 89.44\n",
      "Epoch: [5/10], Step: [301/625], Validation Acc: 89.6\n",
      "Epoch: [5/10], Step: [601/625], Validation Acc: 90.0\n",
      "Learning rate: 0.001, Validation Acc: 90.12\n",
      "Epoch: [6/10], Step: [301/625], Validation Acc: 90.68\n",
      "Epoch: [6/10], Step: [601/625], Validation Acc: 90.76\n",
      "Learning rate: 0.001, Validation Acc: 90.46\n",
      "Epoch: [7/10], Step: [301/625], Validation Acc: 90.5\n",
      "Epoch: [7/10], Step: [601/625], Validation Acc: 90.96\n",
      "Learning rate: 0.001, Validation Acc: 90.84\n",
      "Epoch: [8/10], Step: [301/625], Validation Acc: 91.08\n",
      "Epoch: [8/10], Step: [601/625], Validation Acc: 91.14\n",
      "Learning rate: 0.001, Validation Acc: 91.1\n",
      "Epoch: [9/10], Step: [301/625], Validation Acc: 91.08\n",
      "Epoch: [9/10], Step: [601/625], Validation Acc: 91.12\n",
      "Learning rate: 0.001, Validation Acc: 90.7\n",
      "Epoch: [10/10], Step: [301/625], Validation Acc: 91.18\n",
      "Epoch: [10/10], Step: [601/625], Validation Acc: 91.44\n",
      "Learning rate: 0.001, Validation Acc: 90.96\n"
     ]
    }
   ],
   "source": [
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "max_vocab_size = 50000\n",
    "MAX_SENTENCE_LENGTH = 800\n",
    "emb_dim = 200\n",
    "BATCH_SIZE = 32\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "model = BagOfWords(len(id2token), emb_dim)\n",
    "num_epochs = 10\n",
    "learning_rate = 0.001\n",
    "train_accuracy_final = []\n",
    "val_accuracy_final = []\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (data, lengths, labels) in enumerate(train_loader):\n",
    "        model.train()\n",
    "        data_batch, length_batch, label_batch = data, lengths, labels\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(data_batch, length_batch)\n",
    "        loss = criterion(outputs, label_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # validate every 300 iterations\n",
    "        if i > 0 and i % 300 == 0:\n",
    "            # validate\n",
    "            val_acc = test_model(val_loader, model)\n",
    "            print('Epoch: [{}/{}], Step: [{}/{}], Validation Acc: {}'.format( \n",
    "                        epoch+1, num_epochs, i+1, len(train_loader), val_acc))\n",
    "    trainacc = test_model(train_loader, model)\n",
    "    valacc = test_model(val_loader, model)\n",
    "    train_accuracy_final.append(trainacc)\n",
    "    val_accuracy_final.append(valacc)\n",
    "    print('Learning rate: {}, Validation Acc: {}'.format( \n",
    "                       learning_rate, valacc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3Xl8VNX9//HXyb7vewIk7JDIGpFNFhEELQJKVSpVUOpSra1+u2C1rfWrLbb+XNp+v36LVUCrIIsLFRFFEdCwKyYh7BBCSEIWQvZ1cn5/3EkgJIGQ7c5MPs/HI48kd+7c+eQ+4D1nzj33HKW1RgghhONyMrsAIYQQnUuCXgghHJwEvRBCODgJeiGEcHAS9EII4eAk6IUQwsFJ0AshhIOToBdCCAcnQS+EEA7OxewCAEJCQnRsbKzZZQghhF3Zt29fvtY69Er72UTQx8bGsnfvXrPLEEIIu6KUOtWa/aTrRgghHNwVg14p9aZSKlcplXrRtiCl1OdKqaPW74HW7Uop9Tel1DGlVLJSakRnFi+EEOLKWtOiXw5Mv2TbYuALrXU/4Avr7wAzgH7WrweA1zqmTCGEEG11xT56rfU2pVTsJZtnAZOsP68AvgJ+Y93+ljbmPt6plApQSkVqrbOvtrCamhoyMzOprKy82qcKB+bh4UFMTAyurq5mlyKE3Wjrxdjw+vDWWmcrpcKs26OB0xftl2nd1iTolVIPYLT66dmzZ5MXyMzMxNfXl9jYWJRSbSxTOBKtNQUFBWRmZhIXF2d2OULYjY6+GNtcIje7sonWeqnWOlFrnRga2nR0UGVlJcHBwRLyooFSiuDgYPmUJ8RVamvQn1VKRQJYv+dat2cCPS7aLwbIamtxEvLiUvJvQoir19agXw/ca/35XuCji7bfYx19Mxooakv/vBBCOCRLDZw7CSe3wXfvwJY/Q9Z3nf6yrRleuRLYAQxQSmUqpe4HlgBTlVJHganW3wE+AU4Ax4DXgZ92StVdYNKkSWzatKnRtldeeYWf/vTyf5KPjw8AWVlZzJ07t8VjX+kGsVdeeYXy8vKG32+++WbOnz/fmtJbZejQocybN6/DjieEAGoqIP8oHPsC9i2HL56FdT+BN6fDS4PhuTD42zBYMRM++ilsXQJnvu30sloz6qalNJjSzL4aeKS9RdmCefPmsWrVKm666aaGbatWreKvf/1rq54fFRXF2rVr2/z6r7zyCvPnz8fLywuATz75pM3HutTBgwepq6tj27ZtlJWV4e3t3WHHvlhtbS0uLjZx87UQHaOqBM6fhqLTcD7D+Gr4+TSU5TbeXzmDXzQE9IC4CeDfw/jZvwcE9AT/GHBx7/Sy5X9hC+bOncvTTz9NVVUV7u7upKenk5WVxfjx4yktLWXWrFkUFhZSU1PDc889x6xZsxo9Pz09nR/84AekpqZSUVHBwoULSUtLY9CgQVRUVDTs9/DDD7Nnzx4qKiqYO3cuf/zjH/nb3/5GVlYWkydPJiQkhC1btjRMExESEsJLL73Em2++CcCiRYv4xS9+QXp6OjNmzGD8+PEkJSURHR3NRx99hKenZ5O/7d133+XHP/4xBw8eZP369Q0t+2PHjvHQQw+Rl5eHs7Mza9asoU+fPvzlL3/h7bffxsnJiRkzZrBkyRImTZrEiy++SGJiIvn5+SQmJpKens7y5cvZsGEDlZWVlJWVsX79+hbP1VtvvcWLL76IUoohQ4bwv//7vwwZMoQjR47g6upKcXExQ4YM4ejRozKcUnQ+raGisHFwXxroFYWNn+PsZoR1QE/of5PxPaDnhUD3jQJn82PW/Apa4Y//OUBaVnGHHnNwlB9/mBnf4uPBwcGMGjWKTz/9lFmzZrFq1SruvPNOlFJ4eHjwwQcf4OfnR35+PqNHj+bWW29t8ULha6+9hpeXF8nJySQnJzNixIUbhp9//nmCgoKwWCxMmTKF5ORkHnvsMV566SW2bNlCSEhIo2Pt27ePZcuWsWvXLrTWXHfddUycOJHAwECOHj3KypUref3117njjjtYt24d8+fPb1LPe++9x+eff87hw4f5xz/+0RD0d999N4sXL2bOnDlUVlZSV1fHxo0b+fDDD9m1axdeXl6cO3fuiud2x44dJCcnExQURG1tbbPnKi0tjeeff55vvvmGkJAQzp07h6+vL5MmTWLDhg3Mnj2bVatWcfvtt0vIi/bTGirPQ2kelJ41vorPGGHe0Co/DdUljZ/n6nUhuGMSLwpxa6B7h4GT7c8kYxdBb5b67pv6oK9vRWut+e1vf8u2bdtwcnLizJkznD17loiIiGaPs23bNh577DEAhgwZwpAhQxoeW716NUuXLqW2tpbs7GzS0tIaPX6pr7/+mjlz5jR0t9x2221s376dW2+9lbi4OIYNGwbAyJEjSU9Pb/L8PXv2EBoaSq9evYiJieG+++6jsLAQFxcXzpw5w5w5cwDjxiSAzZs3s3DhwoYupKCgoCuet6lTpzbs19K5+vLLL5k7d27DG1n9/osWLeIvf/kLs2fPZtmyZbz++utXfD3RjVWVWoM71+g2Kc298Hv9z2XWcLdUN32+hz/494TA2MZdKwE9je1eQeAAI73sIugv1/LuTLNnz+aJJ57g22+/paKioqEl/s4775CXl8e+fftwdXUlNjb2imO7m2vtnzx5khdffJE9e/YQGBjIggULrngc4zJI89zdL/T1OTs7N+oiqrdy5UoOHTpE/bTQxcXFrFu3jjvuuKPF12uudhcXF+rq6gCa1Hxxn39L56ql444bN4709HS2bt2KxWIhISGhxb9XOKiaCmtwX9T6vrgl3rA9F2rKmz5fOYFXCPiEg08YhA4wvnuHXdjmEwZ+UUbQdwN2EfRm8fHxYdKkSdx3332NRqgUFRURFhaGq6srW7Zs4dSpy88UOmHCBN555x0mT55MamoqycnJgBGy3t7e+Pv7c/bsWTZu3MikSZMA8PX1paSkpEnXzYQJE1iwYAGLFy9Ga80HH3zA22+/3aq/p66ujjVr1pCcnEx0dDQAW7Zs4bnnnmPRokXExMTw4YcfMnv2bKqqqrBYLEybNo1nn32WH/3oRw1dN0FBQcTGxrJv3z5GjRp12YvOLZ2rKVOmMGfOHB5//HGCg4Mbjgtwzz33MG/ePH73u9+16u8SdkJrKDxpjEq5uOXdqCWeB1VFzT/fM8ga1KEQc63xs3do4/D2CQevYHBy7tq/zcZJ0F/BvHnzuO2221i1alXDtrvvvpuZM2eSmJjIsGHDGDhw4GWP8fDDD7Nw4UKGDBnCsGHDGDVqFGAMcRw+fDjx8fH07t2bcePGNTzngQceYMaMGURGRrJly5aG7SNGjGDBggUNx1i0aBHDhw9vtpvmUtu2bSM6Oroh5MF440hLSyM7O5u3336bBx98kN///ve4urqyZs0apk+fzv79+0lMTMTNzY2bb76ZP/3pT/zyl7/kjjvu4O233+aGG25o8TVbOlfx8fE89dRTTJw4EWdnZ4YPH87y5csbnvP000/L8E97V2eB3DQ4tQMykozvpTmN93H3N4LbJxwirrG2usOaCe8QcHEz5+9wAOpyXQFdJTExUV86rvzgwYMMGjTIpIqEmdauXctHH33U4icV+bdho2qrjZt/MpLgVBJk7LrQOveLgV5jodcYCL/mQoi7Nh0VJlpPKbVPa514pf2kRS9sys9+9jM2btzYofcNiE5SVQKnd0PGDqO1fmYv1Fqv14QMgIQ50NMa7gFNJy4UXUeCXtiUv//972aXIFpSln8h1DOSIDsZtMW4+Bk5FBLvN0K95xjwDrny8USXkaAXQjTvfEbj/vX8w8Z2Fw+IToTrnzBCvccocPc1t1ZxWRL0QghjREze4QuhfioJijONx9z9oed1MPQu6DUOooZ1yW37ouNI0AvRHVlqIef7C6GesQMqrHc9+4QbLfVePze6YsIGy3BFOydBL0R3UFMBmXutoZ4Ep/dATZnxWGAcDLj5Qv96UG+HuBtUXCBB34KCggKmTDEm6MzJycHZ2Zn6lbB2796Nm9uVx/QuXLiQxYsXM2DAgKt67VtuuYXi4mK2b99+9YULAcYY9qz9cPIrOPGVMdTRUgUoCI+H4XdbW+1jwbf5qTuE45Cgb0FwcDD79+8H4JlnnsHHx4df/vKXjfbRWqO1xqmFSY2WLVt21a9bUFBASkoKHh4eZGRkNLuebkeQKYQdjNbGHacnvoKTWyF9O1Rax7CHJ8C1i4y5XHqOBs8AU0sVXc/2p12zMceOHSMhIYGHHnqIESNGkJ2dzQMPPEBiYiLx8fE8++yzDfuOHz+e/fv3U1tbS0BAAIsXL2bo0KGMGTOG3NzcZo+/du1aZs+ezZ133sl7773XsD0nJ4dZs2YxZMgQhg4dyq5duwDjzaR+28KFCwGYP38+H374YcNz6xdD2bx5MzfeeCN33XUXw4cPB2DmzJmMHDmS+Ph4/vWvfzU8Z8OGDYwYMYKhQ4cybdo0LBYLffv2bZi90mKx0Lt371bNZik6SXEW7F8JHzwELw2C/7kWNv4KcpJh8Cy4/Q345TF4+BuY/icYMF1CvpuyjybdxsWQk9Kxx4y4BmYsufJ+zUhLS2PZsmX83//9HwBLlixpmJJ38uTJzJ07l8GDBzd6TlFRERMnTmTJkiU88cQTvPnmmyxevLjJsVeuXMmf//xn/P39mT9/Pr/61a8AeOSRR5g6dSqPPvootbW1lJeX8/333/PCCy+QlJREUFBQq0J3586dpKWlNXxSWLFiBUFBQZSXl5OYmMjtt99OVVUVDz/8MNu3b6dXr16cO3cOZ2dn5s2bx7vvvsujjz7Kpk2buPbaa1s1m6XoIBWFkP41nNhqtNrzjxjbvYKN1nrvSRA3EYLizKxS2CD7CHob06dPH6699tqG31euXMkbb7xBbW0tWVlZpKWlNQl6T09PZsyYARhTCDfX/37mzBkyMjIYPXo0SiksFguHDh1i4MCBfPXVVw3z7bi4uODn58eXX37JnXfe2RC2rQndMWPGNOoOevnll1m/fj0AmZmZHD9+nNOnTzN58mR69erV6Lj3338/P/zhD3n00Ud58803WbRoUavPmWiDmko4vdMI9hNfQfZ+0HXGHOm9xsGIe4xwD4u3iznRhXnsI+jb2PLuLBdPw3v06FFeffVVdu/eTUBAAPPnz292quGLL946OztTW1vbZJ/33nuPgoIC4uKMFllRURGrVq3imWeeAZpOddyaKYQtFkuj17q49s2bN7Nt2zZ27tyJp6cn48ePv+wUwrGxsQQGBrJlyxa+++47pk2b1uz5EW1UZzHC/MRXRrhn7DQuoDq5GDcoTfg19J5o/CwTfImrIM2AdiouLsbX1xc/Pz+ys7ObLCh+NVauXMnmzZtJT08nPT2d3bt3s3LlSgAmT57c0FVksVgoLi7mxhtvZNWqVQ1dNvXf66cQBvjggw+wWCzNvl5RURFBQUF4enpy4MAB9uzZAxhzwn/55ZcNUwpf3CV0//33c/fdd3PXXXe1eBFatJLWkHcEdr8Oq+6Gv8TB6zcYC0qXFxgXUH+0Gn6TDvdvgslPGqNkJOTFVbKPFr0NGzFiBIMHDyYhIaHJVMNX4/jx4+Tk5JCYeGEiun79+uHu7s6+ffv4xz/+wU9+8hP++c9/4uLiwj//+U9GjRrFr3/9ayZMmICLiwsjR47kjTfe4MEHH2TWrFl8/vnnTJs2rdGCJBe75ZZbWLp0KUOHDmXgwIFcd911AISHh/Paa68xa9YstNZERUWxceNGAObMmcN9993HggUL2vR3dnvFWRf62E98BSXZxvaAnsYF1LiJxpdPqKllCsci0xSLq7Jz506efPLJRnPkdzW7+rdRWQwnt10Y9lh/AdUzyOiGiZto9LPLBVTRBjJNsehwzz//PEuXLm20CItoRsFxOLIJjnxq3IlaV2O9gDrWuIAaN9EY2y5dX6KLSNCLVnvqqad46qmnzC7D9tRWG9MKHPnMCPdzx43toQNh9MPQbxr0uE761oVpbDroWxr9IbovW+hqBIw1To9+ZrTcj2+B6hJwdoe46+G6h6D/NAiMNbtKIQAbDnoPDw8KCgoIDg6WsBeAEfIFBQV4eHh0/YvX1RmzPR7ZZHxlfWts942Ea26HfjcZfe5u3pc/jhAmsNmgj4mJITMzk7y8PLNLETbEw8ODmJiYrnmxqhLjIuqRTUbrvfQsoCAmESY/Df1vMu6wloaIsHE2G/Surq4NNw4J0WXOnbjQaj/1DViqwd0P+k4xWu39psoyecLu2GzQC9ElLDXGohv14V5w1Nge0h+ue9AI956jwdnV3DqFaAcJetH9lObBsc+tF1K/hKpicHaD2PHG3aj9pxmLbwjhICTohePT2pi6t77VfmYfoMEnAuJnWy+kTgJ3H5MLFaJzSNALx2SpNVrthzcaF1JLsgEF0SNg0pPWC6lD5KYl0S1I0AvHUlsF+9+Fb16FwpPg5gt9b7hwIdUnzOwKhehyEvTCMVSVwr5lsON/jNZ71HCY+hb0nyF3pIpuT4Je2Lfyc7B7Kez6P2MFptjrYfb/Qu/JMr5dCCsJemGfirNhxz9g7zKoKTNa7tc/AT1GmV2ZEDZHgl7Yl3Mnjf73/e9AXS0k3A7jH4fweLMrE8JmSdAL+3D2AHz9MqSuM5bWG3Y3jHtMxrsL0QoS9MK2nd4D2/8fHNkIrt4w5hEY/Qj4RZpdmRB2o11Br5T6OfATQAGva61fUUo9Y91WPxvZb7XWn7SrStG9aA0ntsD2lyB9O3gGGmPfRz0AXkFmVyeE3Wlz0CulEjACfRRQDXyqlNpgffhlrfWLHVCf6E7q6uDwBqMFn/WdcefqtOdh5AK5a1WIdmhPi34QsFNrXQ6glNoKzOmQqkT3YqmBlLVGH3z+YQiMg5mvwtB54NL8wuZCiNZrT9CnAs8rpYKBCuBmYC9QADyqlLrH+vt/aa0LL32yUuoB4AGAnj17tqMMYbdqKuC7f8M3f4OiDAiLh9vfgMGzwVkuHwnRUVR7lmZTSt0PPAKUAmkYgb8EyAc08N9ApNb6vssdJzExUe/du7fNdQg7U1kMe98w7mIty4OYUXD9fxnzz8hNTkK0mlJqn9Y68Ur7tavZpLV+A3jD+oJ/AjK11mcvKuJ14OP2vIZwIGX5sPM12P06VBVBnxuMgO81TgJeiE7U3lE3YVrrXKVUT+A2YIxSKlJrnW3dZQ5GF4/ozooyIenvsG8F1FbCoJnGXaxRw82uTIhuob0doeusffQ1wCNa60Kl1NtKqWEYXTfpwIPtfA1hr/KPwTcvw/fvARqG3AnjfgGh/c2uTIhupb1dN9c3s+3H7TmmcADZycYQybSPjFEziffB2EchQC66C2EGGdogOk5pLnzxR2MkjbufMQfN6J+CT6jZlQnRrUnQi/arrTamCt76gjFkcuxjxkVWzwCzKxNCIEEv2uvYZvj0Scg/An2nwvQlENLX7KqEEBeRoBdtc+4EbHoKDn9izCD5o9XGOHghhM2RoBdXp6oUvn7JGC7p7AY3/hFGPyxTFQhhwyToRetobcxH8/nvjDVZh9wFNz4j0wULYQck6MWVZX8Pn/waTu+EyGFwx1uyZJ8QdkSCXrSsLB++/G/jjlavYLj17zBsPjg5mV2ZEOIqSNCLpiy1xqRjW56H6jJjLPzEX8twSSHslAS9aOzEV7BxMeQdhN6TYPoLEDbQ5KKEEO0hQS8Mhafgs6fg4H8goBfc+Q4MvEVmlRTCAUjQd3fV5fDNK/DNq6Cc4IanYczPwNXD7MqEEB1Egr670hrSPoRNT0NxJiTMhanPgn+02ZUJITqYBH13lJMKG38Dp76G8Gvg9teh11izqxJCdBIJ+u6k/Jwxkmbvm+ARALe8BCMXgJOz2ZUJITqRBH13UGeBfcvgy+egsgiuXQSTngSvILMrE0J0AQl6R5f+jdFNczYFYq+HGS9AeLzZVQkhupAEvaMqyoTPfgcH3gf/HvDDFTB4lgyXFKIbkqB3NDUVxsyS218CNExcDON+Dm5eZlcmhDCJBL0jObQBPl0M5zOM1vu052SdViGEBL1DKM6GT34Jhz6G0EFwz3roPdHsqoQQNkKC3p7V1RmjaTY/A5ZqmPIHGPszcHY1uzIhhA2RoLdXeUfgP49Bxg6ImwA/eAWC+5hdlRDCBknQ25vaavj6Zdj+Irh6waz/gWF3y2gaIUSLJOjtyendsP4xYwrhhNth+hLwCTO7KiGEjZOgtweVxfDFs7DnX+AXDT9aDf1vMrsqIYSdkKC3dYc+gQ3/ZSzIfd2DxjTC7r5mVyWEsCMS9Laq5Cxs/BWkfQRh8XDn2xCTaHZVQgg7JEFva7SGb9+Cz38HNZVww++MO1tlyKQQoo0k6G1J/jH4z8+NeeJ7jYeZr0JIX7OrEkLYOQl6W1BbDUmvwta/Gkv4zfwbDP8xODmZXZkQwgFI0Jstcy+s/xnkpsHg2TDjL+AbbnZVQrSK1pqyaguFZdWcL6+hsLyawnLj5/rfz5dXU1he0/DdxUkRGeBBpL8nUf4eRAZ4EunvQZT1u6+HdFN2NAl6s1SVGAuB7Pon+EbCXSth4M1mVyW6sRpLHefLayiqMAK5cXjXB3Xj0C4qr6HaUtfiMX09XAj0ciPQy5UALzdiQ7yptWiyiir4+mg+uSWV1Ommz4ny92zyZhBlfTOI8PfAw9V+VkWrrq1rOF8Xv/HVvyFOT4hgRM/ATq1Bgt4MRzbBx09A8RljtacpvwcPP7OrEg6m1lJHXmkV2UWVnC2qJLekqiFcLg3v82U1lFTVtngsV2dFwEWBHRfizQgvt4ZtgV5uBHi5Euh9YR9/T1dcnS/f/VhjqSO3pIrs8xVkFVWSdb6i4efsogpSMosoKKtu8rxgb7dmPxVEB3gSGeBJuK87Lld47aultaa4srZpaJfVNAnvi7+XV1taPKa7ixO9Q7wl6B1Kaa4xjXDqOggdCPd/Bj1GmV2VsEOVNRbOFleSU1RJTnEl2UXWn4sqyS6uJKeogrySqiatZWjcyg70cqN3iLc1sN0I9HZtGt5ebni5OaM6YZoNV2cnogM8iQ7wvOzfmmN9E8gqqmz0RpBRUM7O4wVN3qScFIT5ehAZ4GF8OrC+GURb3xwiAzzQGuMNr0lQN/7UUlheTVF5DecrarA0d0IxZiDx97xwzsL9PBgQ4Wv87ulKgHfTcxro5YanW9d8MpGg7wpaw/53YNNTUFMOk5+Ccb8AFzezKxM2qKSypmmAW0M9u6iSs8WVnGumlevr7kKEvwcR/h70Dwsl0t+DCH9PIvzdifDzJMzPnQBP1w5v6XY2D1dnYkO8iQ3xbnGfksoasus/EVz0ZpB1voK07GI2HzxLVW3LXUyNX8/JGshGOA+K8GsI5wAv10afbOrD28/TFWcn251vSoK+sxUch49/ASe3Qc+xxpDJ0P5mVyVMoLXmXFl1Q1g3DfEKzhZXUdpMF0qwtxsR/h5E+XswomfAhRD382gIdx/37vvf2dfDFV8PV/qHN3/XuNaawvKaC28ERRU4KdXo+kGgtxHa9tT/31rd919GZ7PUGEv6bX0BnN3gBy/DiAUyZNIB1YdIbkklucVV5JZUkVdSZfxeUkVecRXZxUaIV1/SqnR2UoT5uhut8HBfJvQ3WuLhftYuBn8PwvzccXdxvPDpSkopgrzdCPJ2IyHa3+xyupwEfWc4860xy+TZFBg0E2b8Ffwiza5KXKUaSx35pVUN4V0f5HnWbXnWIM8vraLG0rTv1sfdhVBfd0J93RnRM5AIfw8iG1rgRoiH+Ljb9Ed+4RjaFfRKqZ8DPwEU8LrW+hWlVBDwHhALpAN3aK0L21mnfagugy+fh12vgXcY3PlvI+iFTSmrqm3c6r6kFW58r2q2HxyMbpT6AO8b5kuYnzth1t/DfD0afvbuxl0pwra0+V+iUioBI+RHAdXAp0qpDdZtX2itlyilFgOLgd90RLE27ehm+PhxKMqAxPvgxmfAo/t9RLQF+aVVHMgq5lB2MTnFlQ0hnldSRW5xJWXNDHdzdVaE+rgT6udBjyAvRvYKbBTcYX5GeIf4uF9xyKAQtqY9TY5BwE6tdTmAUmorMAeYBUyy7rMC+ApHD/pvXoXPfw8h/WHhp9BrjNkVdQtaa7KKKjlwpojUrGLSsopIPWOEe72Lu0/io/yYPCDMCG0fd2tL3AjyAC/XThk+KIQtaE/QpwLPK6WCgQrgZmAvEK61zgbQWmcrpZpdAkkp9QDwAEDPnj3bUYbJ6iyQ9A/oPclYEMTF3eyKHFJdnSa9oIwDWcWkZhVx4EwxB7KKKCyvAYxx031CfRjdO4iEaH8GR/kRH+mPv5fcTi9Em4Nea31QKfUC8DlQCnwPtHxrXdPnLwWWAiQmJjZ/F4I9OLkVynIh8UUJ+Q5SY6njWG4pqWeKOJBlBHpaVnFDl4urs2JAhC83xUcQH+VHfLQ/gyL8uuzmEyHsTbuuFmmt3wDeAFBK/QnIBM4qpSKtrflIILf9ZdqwlLXg7gf9ZGm/tqissXAop6RRqB/KKWkYhujl5sygSD/mjowhPsqf+Gg/+oX54uYi/eRCtFZ7R92Eaa1zlVI9gduAMUAccC+wxPr9o3ZXaatqKiBtPQyeZUwvLC6rpLKGtKxiUrOKOWAN9mN5pQ23lft7upIQ7ceCsbFGSz3Kn7gQbxl+KEQ7tXf81zprH30N8IjWulAptQRYrZS6H8gAftjeIm3WkU1QXQLXzDW7EptTP/LlwEX96ekF5Q2Ph/u5Ex/lz03x4QyO8ich2o/oAE+5ICpEJ2hv1831zWwrAKa057h2I2UN+ERA3ASzKzGd1prvM4vYkJzFpwdyOH2uouGxnkFexEf58cPEHg0t9VBfuZ4hRFeROzraqqIQjn4G1/4EnLrnRUCtNSlnitiQnM3HydmcOV+Bq7Pi+n6h3DsmlvgoY/SLv6eMfBHCTBL0bZW2HizV3a7bRmvNgaxiPk7OZkNKFqfPVeDipLi+XwiPT+3P1MHhEuxC2BgJ+rZKWQPBfSFquNmVdDqtNWnZxWxIzmZDSjanCspxcVKM6xvCz27ox7TB4QR4yZTLQtgqCfq2KM6C9K9h0mJjxQEHpLXmUE7REZN3AAARd0lEQVRJQ7ifzC/D2Ukxtk8wP53Uh2mDIwj0lnAXwh5I0LdFylpAwzWONaBIa82Rs6VsSM7i45RsTuSV4aRgbJ8QHpjQm5viIwiScBfC7kjQt0XKGogaAcF9zK6kQxw9W2Ltc8/mWG4pTgpG9w7m/vFxTI+PINhHRsgIYc8k6K9W3mHISYbpS8yupF2O5ZawITmHDSlZHDlbilIwOi6Ye8fGMj0+QoY/CuFAJOivVsoaUE4Qf5vZlVy143mlfGJtuR/KKUEpGBUbxH/PiuemhAjCfOXuXiEckQT91dDaCPq4ieAbbnY1rXIyv4xPUoxx7gezi1EKru0VxB9vjWdGQgRhfhLuQjg6CfqrkbkXCtNhwq/NruSyThWUsSElmw3J2RzIKgYgsVcgf5g5mBkJkUT4S7gL0Z1I0F+NlNXg4mFzywPW1Rnj3LceyePT1BxSzhQBMKJnAL/7wWBmJEQQFeBpcpVCCLNI0LeWpRZS34f+08HDz+xqyC+tYvvRPLYezmP70XwKrOubDu0RwNO3DGLGNZFES7gLIZCgb70TX0F5vmlj52ssdew7Vci2I3lsO5pH6hmjSybY243r+4UwcUAo4/uGymgZIUQTEvStlbLGWOy739Que8nT58r56kge247kseN4AaVVtbg4KUb0CuRXNw1gQr9Q4qP8cJL52oUQlyFB3xrV5XDoY0i4rVOXCyyvrmXniQK2Hcln65E8TuaXARAT6Mmtw6KY2D+UsX2C8fWQScOEEK0nQd8ahz+B6lK45o4OPazWmsNnS9h62OiO2XOykGpLHR6uTozpHcw9Y3oxsX8ocSHesiCHEKLNJOhbI2Ut+EZBr3HtPlRhWTVfHzNa7NuP5nG2uAqAAeG+LBgXy4R+oSTGBuLh2j3nuBdCdDwJ+ispPwfHPofRD4PT1S9IXWup4/vM82w9ks+2I3l8n3kerY31Ucf3C2Fi/1Am9AuVse1CiE4jQX8laR9CXe1VjbbJOl/RMDrm66P5FFfW4qSMoY8/n9KPCf1DGRoTIIteCyG6hAT9lSSvgZABEDGkxV1qLHXsOF7AtiN5bD2Sx9HcUgAi/DyYnhDBxP5hjOsbLItzCCFMIUF/OedPQ0YSTH76sguMPPl+Cmv3ZeLm4sR1cUHckdiDCf1D6R/uIxdRhRCmk6C/nNS1xvfLrAubU1TJB9+d4a5re/CHmfF4uslFVCGEbbn6q4vdScpaiLkWguJa3OWdXaeo05qfTuorIS+EsEkS9C05mwZnUy87dr6q1sLK3RlMGRhGz2CvLixOCCFaT4K+JSlrQDlD/JwWd9mQnE1+aTX3jo3turqEEOIqSdA3p67O6LbpMxl8QpvdRWvN8qR0+oR6M75vSBcXKIQQrSdB35zTu6Ao47LdNt+dPk9yZhH3jo2VkTVCCJsmQd+clDXg4gkDb25xlxVJ6fi4u3DbiJguLEwIIa6eBP2lLDVw4AMj5N19m90lt6SST1KymTsyBh93GaEqhLBtEvSXOv4lVJy77JQH7+7KoMai5SKsEMIuSNBfKnk1eAZCnynNPlxdW8c7uzKYNMCYPlgIIWydBP3FqkqNuecHzwaX5uel2ZiaTV5JlbTmhRB2Q4L+Yoc/gZpyGNLyaJvlSenEhXgzsV/zwy6FEMLWSNBfLGUN+MVAj9HNPpyceZ7vMs7z49G9ZJ1WIYTdkKCvV5YPx74wJjBrYYGR5UnpeLs5MzdRhlQKIeyHBH29Ax+AtrQ42ia/tIqPv8/m9pEx+Mni3EIIOyJBXy9lDYQNhoiEZh9etTuDaksd94yJ7dq6hBCinSToAQrTjWkPWmjN11jq+PfODK7vF0LfMJ+urU0IIdpJgh6MCcygxQVGNh3IIae4knulNS+EsEPtCnql1ONKqQNKqVSl1EqllIdSarlS6qRSar/1a1hHFdsptDa6bXqOgYCeze6yIimdHkGeTB4Y1sXFCSFE+7U56JVS0cBjQKLWOgFwBu6yPvwrrfUw69f+Dqiz85xNhbxDLbbmD2QVsSe9kHvHxOIsQyqFEHaovV03LoCnUsoF8AKy2l9SF0teDU4uMLj5BUZWJKXj6erMDxN7dHFhQgjRMdoc9FrrM8CLQAaQDRRprT+zPvy8UipZKfWyUsq9A+rsHHV1kLrOmNfGO7jJw+fKqvlofxZzRkTj7ylDKoUQ9qk9XTeBwCwgDogCvJVS84EngYHAtUAQ8JsWnv+AUmqvUmpvXl5eW8ton4wkKD7T4pQHq/ZkUFVbJxdhhRB2rT1dNzcCJ7XWeVrrGuB9YKzWOlsbqoBlwKjmnqy1Xqq1TtRaJ4aGmjRvTMoacPWGATOaPFRrqePfO04xpncwAyKan5deCCHsQXuCPgMYrZTyUsZaelOAg0qpSADrttlAavvL7AS11XDgQxh4C7g1nW5488GzZBVVyiyVQgi71+blkbTWu5RSa4FvgVrgO2ApsFEpFQooYD/wUEcU2uGObYbK8y3eJLU8KZ3oAE9uHCRDKoUQ9q1d6+Bprf8A/OGSzTe055hdJmU1eAVDn8lNHjqUU8zOE+dYPGMgLs5yT5kQwr51zxSrLIbDGyH+NnBuOppmRdIp3F2cuFOGVAohHED3DPpDG6C2stlum/Pl1XzwXSazh0UT6N38KlNCCGFPumfQp6w2pjvo0XRA0Oq9p6msqZOLsEIIh9H9gr40F058ZbTmVeMpDSx1mrd2nGJUXBCDo/zMqU8IITpY9wv61PdB18E1TW+S+vJQLpmFFSyQ1rwQwoF0v6BPWQPh10DYwCYPrUhKJ9Lfg2mDw00oTAghOkf3CvqC43BmLwxpehH26NkSvj6Wz/zRvWRIpRDCoXSvREtdByhIuL3JQyt2pOPm4sRd18qQSiGEY+k+Qa+1MSVxr3HgH9PooeLKGt7/9gwzh0QR7GO7k20KIURbdJ+gz/4eCo42u8DImr2ZlFdb5CKsEMIhdZ+gT1kDTq4weFajzXV1mrd3pDOyVyDXxPibU5sQQnSi7hH0dRZjAfB+U8ErqNFDW4/kkV5QLjdICSEcVvcI+vSvoTSn2SkPlielE+brzoyECBMKE0KIztc9gj5lNbj5NFlg5HheKVuP5HH3db1wlSGVQggH5fjpVlMJaf+BQTPB1bPRQ2/vOIWrs2LedTKkUgjhuBw/6I9+BlVFTbptSqtqWbsvkx8MiSLM18Ok4oQQovM5ftCnrAHvUIib2Gjzun2ZlFbVykVYIYTDc+ygryyCI5uMO2GdLyymVVenWbEjnaE9AhjWI8C8+oQQogs4dtAf/A9Yqpp023x9LJ8TeWUsGNvLpMKEEKLrOHbQJ6+GwDiIHtlo8/KkdEJ83Lj5mkiTChNCiK7juEFfkgMntzVZYORUQRlbDufyo+t64e7ibGKBQgjRNRw36FPXAbpJt81bO07hrBR3X9fTnLqEEKKLOW7QJ6+GyKEQ2r9hU1lVLav3nmbGNZGE+8mQSiFE9+CYQZ9/FLL3N1ku8IPvzlBSWSsXYYUQ3YpjBn3KGi5dYERrzYqkdBKi/RjRM9C82oQQoos5XtBrbQR93PXgd2FUTdLxAo7mlnLvmFjURRdnhRDC0Tle0J/5Fs6daNJtszwpnSBvN2YOjTKpMCGEMIfjBX3KGnB2MyYxszp9rpwvDp5l3qgeeLjKkEohRPfiWEFvqTWGVfa/CTwvTG3w752nUEoxf7RchBVCdD+OFfTp26Ast9HY+YpqC6v2nOam+HAi/T0v82QhhHBMjhX0yWvA3Q/63dSw6cP9ZyiqqOHeMbHm1SWEECZynKCvqTAmMRt0K7gaN0PVD6kcGOHLqLigKxxACCEck+ME/ZFPoboEhlzottl18hyHckpYOE6GVAohui/HCfrkNeATAbHXN2xakZROgJcrs4ZFm1iYEEKYyzGCvqLQWDIw4XZwMoZPZp2v4LO0s9x5rQypFEJ0b44R9GkfQV0NXDO3YdO/d55Ca82PZUilEKKbc4ygT1kLwX0hajgAlTUWVu7O4MZB4cQEeplcnBBCmMv+g77oDKR/bUx5YL3guv77LArLa1gwLtbc2oQQwgbYf9A3LDBidNvUD6kcEO7LmN7B5tYmhBA2oF1Br5R6XCl1QCmVqpRaqZTyUErFKaV2KaWOKqXeU0q5dVSxzUpZbawJG9wHgH2nCjmQVcw9Y3vJkEohhKAdQa+UigYeAxK11gmAM3AX8ALwsta6H1AI3N8RhTYr9xDkpDSa8mB5Ujp+Hi7MGS5DKoUQAtrfdeMCeCqlXAAvIBu4AVhrfXwFMLudr9Gy1HWgnCD+NgByiir5NDWHOxJ74OXm0mkvK4QQ9qTNaai1PqOUehHIACqAz4B9wHmtda11t0yg85rW4x+H2PHgGw7AO7tOYdGae2ReGyGEaNCerptAYBYQB0QB3sCMZnbVLTz/AaXUXqXU3ry8vLYV4eYFvScCUFVrDKmcMjCMnsEypFIIIeq1p+vmRuCk1jpPa10DvA+MBQKsXTkAMUBWc0/WWi/VWidqrRNDQ0PbUYZhQ3I2+aXV3Ds2tt3HEkIIR9KeoM8ARiulvJQxvGUKkAZsAepvUb0X+Kh9JbbOiqR0+oR6M75vSFe8nBBC2I02B73WehfGRddvgRTrsZYCvwGeUEodA4KBNzqgzsv6LqOQ7zOLuHeszFIphBCXatfQFK31H4A/XLL5BDCqPce9WsuT0vFxd+G2ETFd+bJCCGEX7P7O2NySSj5JyWbuyBh83GVIpRBCXMrug/7dXRnUWLRchBVCiBbYddBX19bxzq4MJg0IJS7E2+xyhBDCJtl10G9MzSavpEpa80IIcRl2HfQ+7i5MHRzOxH7tH4cvhBCOyq6vXk4ZFM6UQeFmlyGEEDbNrlv0QgghrkyCXgghHJwEvRBCODgJeiGEcHAS9EII4eAk6IUQwsFJ0AshhIOToBdCCAentG52pb+uLUKpPOBUG58eAuR3YDn2Ts5HY3I+LpBz0ZgjnI9eWusrTg1gE0HfHkqpvVrrRLPrsBVyPhqT83GBnIvGutP5kK4bIYRwcBL0Qgjh4Bwh6JeaXYCNkfPRmJyPC+RcNNZtzofd99ELIYS4PEdo0QshhLgMuw56pdR0pdRhpdQxpdRis+sxi1Kqh1Jqi1LqoFLqgFLq52bXZAuUUs5Kqe+UUh+bXYvZlFIBSqm1SqlD1n8nY8yuySxKqcet/09SlVIrlVIeZtfU2ew26JVSzsD/ADOAwcA8pdRgc6syTS3wX1rrQcBo4JFufC4u9nPgoNlF2IhXgU+11gOBoXTT86KUigYeAxK11gmAM3CXuVV1PrsNemAUcExrfUJrXQ2sAmaZXJMptNbZWutvrT+XYPwnjja3KnMppWKAW4B/mV2L2ZRSfsAE4A0ArXW11vq8uVWZygXwVEq5AF5Alsn1dDp7Dvpo4PRFv2fSzcMNQCkVCwwHdplbieleAX4N1JldiA3oDeQBy6xdWf9SSnmbXZQZtNZngBeBDCAbKNJaf2ZuVZ3PnoNeNbOtWw8hUkr5AOuAX2iti82uxyxKqR8AuVrrfWbXYiNcgBHAa1rr4UAZ0C2vaSmlAjE++ccBUYC3Umq+uVV1PnsO+kygx0W/x9ANPoK1RCnlihHy72it3ze7HpONA25VSqVjdOndoJT6t7klmSoTyNRa13/KW4sR/N3RjcBJrXWe1roGeB8Ya3JNnc6eg34P0E8pFaeUcsO4oLLe5JpMoZRSGP2vB7XWL5ldj9m01k9qrWO01rEY/y6+1Fo7fKutJVrrHOC0UmqAddMUIM3EksyUAYxWSnlZ/99MoRtcmHYxu4C20lrXKqUeBTZhXDl/U2t9wOSyzDIO+DGQopTab932W631JybWJGzLz4B3rI2iE8BCk+sxhdZ6l1JqLfAtxmi17+gGd8jKnbFCCOHg7LnrRgghRCtI0AshhIOToBdCCAcnQS+EEA5Ogl4IIRycBL0QQjg4CXohhHBwEvRCCOHg/j/oqXKTc5FbggAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(10), val_accuracy_final, label=\"Validation Accuracy\")\n",
    "plt.plot(range(10), train_accuracy_final, label=\"Train Accuracy\")\n",
    "plt.legend(loc = 'best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.008"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(test_loader, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model prediction interpretation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(loader, model):\n",
    "    \"\"\"\n",
    "    Help function that tests the model's performance on a dataset\n",
    "    @param: loader - data loader for the dataset to test against\n",
    "    \"\"\"\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model.eval()\n",
    "    for data, lengths, labels in loader:\n",
    "        data_batch, length_batch, label_batch = data, lengths, labels\n",
    "        outputs = F.softmax(model(data_batch, length_batch), dim=1)\n",
    "        predicted = outputs.max(1, keepdim=True)[1]\n",
    "        \n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels.view_as(predicted)).sum().item()\n",
    "    return (100 * correct / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
